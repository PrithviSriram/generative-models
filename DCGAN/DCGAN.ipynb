{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "[python读取MNIST image数据](http://blog.csdn.net/u010165147/article/details/50599490)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip, struct, os\n",
    "\n",
    "def _read(image, label):\n",
    "    minist_dir = './data/mnist'\n",
    "    with gzip.open(os.path.join(minist_dir, label)) as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        label = np.fromstring(flbl.read(), dtype=np.int8)\n",
    "    with gzip.open(os.path.join(minist_dir, image), 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        image = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(label), rows, cols)\n",
    "    return image,label\n",
    "\n",
    "def read_data():\n",
    "    train_img, train_label = _read(\n",
    "            'train-images-idx3-ubyte.gz', \n",
    "            'train-labels-idx1-ubyte.gz')\n",
    "    test_img, test_label = _read(\n",
    "            't10k-images-idx3-ubyte.gz', \n",
    "            't10k-labels-idx1-ubyte.gz')\n",
    "    return train_img, train_label, test_img, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data_2():\n",
    "    trX,trY,teX,teY = read_data()\n",
    "    \n",
    "    # 由于生成网络是无监督任务，不需要测试集，\n",
    "    # 所以把训练和测试两部分数据合并\n",
    "    X = np.concatenate((trX, teX), axis=0)\n",
    "    y = np.concatenate((trY, teY), axis=0)\n",
    "    \n",
    "    # 打乱排序\n",
    "    seed = 547\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(X)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(y)\n",
    "    # 把标签格式变成one-hot\n",
    "    y_vec = np.zeros((len(y), 10), dtype=np.float)\n",
    "    for i, label in enumerate(y):\n",
    "        y_vec[i, y[i]] = 1.0\n",
    "        \n",
    "    return X.astype(np.float)/255, y_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers.python.layers import batch_norm as batch_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 常数偏置\n",
    "def bias(name, shape, bias_start = 0.0, trainable = True):\n",
    "    dtype = tf.float32\n",
    "    var = tf.get_variable(name, shape, tf.float32, trainable = trainable, \n",
    "                          initializer = tf.constant_initializer(\n",
    "                              bias_start, dtype = dtype))\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 随机权重\n",
    "def weight(name, shape, stddev = 0.02, trainable = True):\n",
    "    dtype = tf.float32\n",
    "    var = tf.get_variable(name, shape, tf.float32, trainable = trainable, \n",
    "                          initializer = tf.random_normal_initializer(\n",
    "                              stddev = stddev, dtype = dtype))\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 全连接层\n",
    "def fully_connected(value, output_shape, name = 'fully_connected', with_w = False):\n",
    "    shape = value.get_shape().as_list()\n",
    "    with tf.variable_scope(name):\n",
    "        weights = weight('weights', [shape[1], output_shape], 0.02)\n",
    "        biases = bias('biases', [output_shape], 0.0)\n",
    "    if with_w:\n",
    "        return tf.matmul(value, weights) + biases, weights, biases\n",
    "    else:\n",
    "        return tf.matmul(value, weights) + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Leaky-ReLU层\n",
    "def lrelu(x, leak = 0.2, name = 'lrelu'):\n",
    "    with tf.variable_scope(name):\n",
    "        return tf.maximum(x, leak * x, name = name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ReLU层\n",
    "def relu(value, name = 'relu'):\n",
    "    with tf.variable_scope(name):\n",
    "        return tf.nn.relu(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 反卷积层\n",
    "def deconv2d(value, output_shape, k_h = 5, k_w = 5, strides = [1, 2, 2, 1], name = 'deconv2d', with_w = False):\n",
    "    with tf.variable_scope(name):\n",
    "        weights = weight('weights', \n",
    "                         [k_h, k_w, output_shape[-1], value.get_shape()[-1]])\n",
    "        deconv = tf.nn.conv2d_transpose(value, weights, output_shape, strides = strides)\n",
    "        biases = bias('biases', [output_shape[-1]])\n",
    "        deconv = tf.reshape(tf.nn.bias_add(deconv, biases), deconv.get_shape())\n",
    "        if with_w:\n",
    "            return deconv, weights, biases\n",
    "        else:\n",
    "            return deconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 卷积层\n",
    "def conv2d(value, output_dim, k_h = 5, k_w = 5, strides = [1, 2, 2, 1], name = 'conv2d'):\n",
    "    with tf.variable_scope(name):\n",
    "        weights = weight('weights', \n",
    "                         [k_h, k_w, value.get_shape()[-1], output_dim])\n",
    "        conv = tf.nn.conv2d(value, weights, strides = strides, padding = 'SAME')\n",
    "        biases = bias('biases', [output_dim])\n",
    "        conv = tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape())\n",
    "        return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch Normalization层\n",
    "def batch_norm_layer(value, is_train = True, name = 'batch_norm'):\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        if is_train:\n",
    "            return batch_norm(value, decay = 0.9, epsilon = 1e-5, scale = True,\n",
    "                              is_training = is_train, \n",
    "                              updates_collections = None, scope = scope)\n",
    "        else:\n",
    "            return batch_norm(value, decay = 0.9, epsilon = 1e-5, scale = True, \n",
    "                              is_training = is_train, reuse = True, \n",
    "                              updates_collections = None, scope = scope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "\n",
    "# 保存图片\n",
    "def save_images(images, size, path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Save the samples images\n",
    "    The best size number is\n",
    "            int(max(sqrt(image.shape[0]),sqrt(image.shape[1]))) + 1\n",
    "    example:\n",
    "        The batch_size is 64, then the size is recommended [8, 8]\n",
    "        The batch_size is 32, then the size is recommended [6, 6]\n",
    "    \"\"\"\n",
    "    \n",
    "    # 图片归一化，主要用于生成器输出是tanh形式的归一化\n",
    "    img = (images + 1.0) / 2.0\n",
    "    h, w = img.shape[1], img.shape[2]\n",
    "    \n",
    "    # 生成一个大画布，用来保存生成的batch_size个图像\n",
    "    merge_img = np.zeros((h * size[0], w * size[1], 3))\n",
    "    \n",
    "    # 循环把画布各个位置的值赋为batch里各幅图像的值\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        merge_img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
    "        \n",
    "    # 保存画布\n",
    "    return scipy.misc.imsave(path, merge_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义生成器\n",
    "def generator(z, train = True):\n",
    "    # 经过一个全连接，BN 和激活层 ReLu\n",
    "    h1 = tf.nn.relu(batch_norm_layer(fully_connected(z, 1024, 'g_fully_connected1'), \n",
    "                                     is_train = train, name = 'g_bn1'))\n",
    "    \n",
    "    h2 = tf.nn.relu(batch_norm_layer(fully_connected(h1, 128 * 49, 'g_fully_connected2'), \n",
    "                                     is_train = train, name = 'g_bn2'))\n",
    "    h2 = tf.reshape(h2, [64, 7, 7, 128], name = 'h2_reshape')\n",
    "\n",
    "    h3 = tf.nn.relu(batch_norm_layer(deconv2d(h2, [64,14,14,128], \n",
    "                                              name = 'g_deconv2d3'), \n",
    "                                              is_train = train, name = 'g_bn3'))\n",
    "    \n",
    "    # 经过一个 sigmoid 函数把值归一化为 0~1 之间，\n",
    "    h4 = tf.nn.sigmoid(deconv2d(h3, [64, 28, 28, 1], \n",
    "                                name = 'g_deconv2d4'), name = 'generate_image')\n",
    "    \n",
    "    return h4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义判别器\n",
    "def discriminator(image):\n",
    "    # 卷积，激活，串联条件\n",
    "    h1 = lrelu(\n",
    "            conv2d(image, 11, name = 'd_conv2d1'),\n",
    "            name = 'd_lrelu1')\n",
    "    \n",
    "    h2 = lrelu(\n",
    "            batch_norm_layer(\n",
    "                conv2d(h1, 74, name = 'd_conv2d2'),\n",
    "                name = 'd_bn2'),\n",
    "            name = 'd_lrelu2')\n",
    "    h2 = tf.reshape(h2, [BATCH_SIZE, -1], name = 'reshape_lrelu2_to_2d')\n",
    "    \n",
    "    h3 = lrelu(\n",
    "            batch_norm_layer(\n",
    "                fully_connected(h2, 1024, name = 'd_fully_connected3'),\n",
    "                name = 'd_bn3'),\n",
    "            name = 'd_lrelu3')\n",
    "    \n",
    "    # 全连接层\n",
    "    h4 = fully_connected(h3, 1, name = 'd_result_without_sigmoid')\n",
    "    \n",
    "    return tf.nn.sigmoid(h4, name = 'd_result_with_sigmoid'), h4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义训练过程中的采样函数\n",
    "def sampler(z, train = True):\n",
    "    return generator(z, train = train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    # 设置global_step，用来记录训练过程中的step\n",
    "    global_step = tf.Variable(\n",
    "        0, name = 'global_step', trainable = False\n",
    "    )\n",
    "    # 训练过程中的日志保存文件\n",
    "    train_dir = './logs'\n",
    "    \n",
    "    # 放置三个placeholder，y表示约束条件，images表示送入判别器的图片，\n",
    "    # z表示随机噪声\n",
    "    #y = tf.placeholder(tf.float32, [BATCH_SIZE, 10], name = 'y')\n",
    "    images = tf.placeholder(\n",
    "        tf.float32, [BATCH_SIZE, 28, 28, 1], \n",
    "        name = 'real_images'\n",
    "    )\n",
    "    z = tf.placeholder(\n",
    "        tf.float32, [None, 100], name = 'z'\n",
    "    )\n",
    "    \n",
    "    with tf.variable_scope(tf.get_variable_scope()) as scope:\n",
    "        # 由生成器生成图像\n",
    "        G = generator(z)\n",
    "        # 真实图像送入判别器\n",
    "        D, D_logits = discriminator(images)\n",
    "        # 重用变量\n",
    "        scope.reuse_variables()\n",
    "        # 生成图像送入判别器\n",
    "        D_, D_logits_ = discriminator(G)\n",
    "        # 采样器采集图像\n",
    "        samples = sampler(z)\n",
    "    \n",
    "    # 损失计算\n",
    "    d_loss_real = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits = D_logits, labels = tf.ones_like(D)\n",
    "        )\n",
    "    )\n",
    "    d_loss_fake = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits = D_logits_, labels = tf.zeros_like(D_)\n",
    "        )\n",
    "    )\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    g_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits = D_logits_, labels = tf.ones_like(D_)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # 总结操作\n",
    "    z_sum = tf.summary.histogram('z', z)\n",
    "    d_sum = tf.summary.histogram('d', D)\n",
    "    d__sum = tf.summary.histogram('d_', D_)\n",
    "    g_sum = tf.summary.image('G', G)\n",
    "    \n",
    "    d_loss_real_sum = tf.summary.scalar(\n",
    "        'd_loss_real', d_loss_real\n",
    "    )\n",
    "    d_loss_fake_sum = tf.summary.scalar(\n",
    "        'd_loss_fake', d_loss_fake\n",
    "    )\n",
    "    d_loss_sum = tf.summary.scalar('d_loss', d_loss)\n",
    "    g_loss_sum = tf.summary.scalar('g_loss', g_loss)\n",
    "    \n",
    "    # 合并各自的总结\n",
    "    G_sum = tf.summary.merge(\n",
    "        [z_sum, d__sum, g_sum, d_loss_fake_sum, g_loss_sum]\n",
    "    )\n",
    "    D_sum = tf.summary.merge(\n",
    "        [z_sum, d_sum, d_loss_real_sum, d_loss_sum]\n",
    "    )\n",
    "    \n",
    "    # 生成器和判别器需要更新的变量\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if 'd_' in var.name]\n",
    "    g_vars = [var for var in t_vars if 'g_' in var.name]\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    # 优化算法\n",
    "    # 查看https://github.com/tensorflow/tensorflow/issues/6220\n",
    "    d_optim = tf.train.AdamOptimizer(\n",
    "        0.0002, beta1 = 0.5\n",
    "    ).minimize(\n",
    "        d_loss,\n",
    "        var_list = d_vars,\n",
    "        global_step = global_step\n",
    "    )\n",
    "    g_optim = tf.train.AdamOptimizer(\n",
    "        0.0002, beta1 = 0.5\n",
    "    ).minimize(\n",
    "        g_loss, \n",
    "        var_list = g_vars, \n",
    "        global_step = global_step\n",
    "    )\n",
    "    \n",
    "    # session\n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    writer = tf.summary.FileWriter(train_dir, sess.graph)\n",
    "    \n",
    "    # \n",
    "    data_x, _ = read_data_2()\n",
    "    sample_z = np.random.uniform(-1, 1, size=(BATCH_SIZE, 100))\n",
    "    sess.run(init)\n",
    "    \n",
    "    # 循环整个数据集25次\n",
    "    index = 1\n",
    "    for epoch in range(25):\n",
    "        batch_idxs = 1093\n",
    "        for idx in range(batch_idxs):\n",
    "            batch_images = data_x[idx * 64 : (idx + 1) * 64] \\\n",
    "                            .reshape([64, 28, 28, 1])\n",
    "            batch_z = np.random.uniform(-1, 1, size=(BATCH_SIZE, 100))\n",
    "            \n",
    "            # 更新D\n",
    "            _, summary_str = sess.run(\n",
    "                [d_optim, D_sum],\n",
    "                feed_dict = {\n",
    "                    images: batch_images, \n",
    "                    z: batch_z\n",
    "                }\n",
    "            )\n",
    "            writer.add_summary(summary_str, index)\n",
    "            \n",
    "            # 更新G两次\n",
    "            _, summary_str = sess.run(\n",
    "                [g_optim, G_sum],\n",
    "                feed_dict = {\n",
    "                    z: batch_z\n",
    "                }\n",
    "            )\n",
    "            writer.add_summary(summary_str, index)\n",
    "            \n",
    "            _, summary_str = sess.run(\n",
    "                [g_optim, G_sum],\n",
    "                feed_dict = {\n",
    "                    z: batch_z\n",
    "                }\n",
    "            )\n",
    "            writer.add_summary(summary_str, index)\n",
    "            \n",
    "            index = index + 1\n",
    "            \n",
    "            # 计算训练过程中的损失，打印出来\n",
    "            errD_fake, errD_real, errG = sess.run(\n",
    "                [d_loss_fake, d_loss_real, g_loss],\n",
    "                feed_dict = {\n",
    "                    images: batch_images,\n",
    "                    z: batch_z\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            if idx % 20 == 0:\n",
    "                print('Epoch: [%2d] [%4d/%4d] d_loss: %.8f, g_loss: %.8f' \\\n",
    "                      % (epoch, idx, batch_idxs, errD_fake + errD_real, errG))\n",
    "            \n",
    "            # 每更新100个batch就采样一次并保存到\n",
    "            # /home/lyy/文档/Jupyter Notebook/DCGAN/samples\n",
    "            if idx % 100 == 1:\n",
    "                sample = sess.run(samples, feed_dict = {z: sample_z})\n",
    "                samples_path = './samples'\n",
    "                save_images(\n",
    "                    sample, [8, 8], \n",
    "                    os.path.join(\n",
    "                        samples_path, \n",
    "                        'test_%d_epoch_%d.png' % (epoch, idx)\n",
    "                    )\n",
    "                )\n",
    "                print('save down')\n",
    "                \n",
    "            # 每更新500个batch就保存一次模型\n",
    "            if idx % 500 == 2:\n",
    "                checkpoint_path = os.path.join(train_dir, 'DCGAN_model.ckpt')\n",
    "                saver.save(sess, checkpoint_path, global_step = idx + 1)\n",
    "    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [   0/1093] d_loss: 1.57801890, g_loss: 0.54761648\n",
      "save down\n",
      "Epoch: [ 0] [  20/1093] d_loss: 1.50487578, g_loss: 0.53531468\n",
      "Epoch: [ 0] [  40/1093] d_loss: 1.48597860, g_loss: 0.54527986\n",
      "Epoch: [ 0] [  60/1093] d_loss: 1.41146767, g_loss: 0.57105857\n",
      "Epoch: [ 0] [  80/1093] d_loss: 1.34436572, g_loss: 0.59605885\n",
      "Epoch: [ 0] [ 100/1093] d_loss: 1.26468372, g_loss: 0.62694478\n",
      "save down\n",
      "Epoch: [ 0] [ 120/1093] d_loss: 1.32828057, g_loss: 0.63549292\n",
      "Epoch: [ 0] [ 140/1093] d_loss: 1.26377702, g_loss: 0.65069610\n",
      "Epoch: [ 0] [ 160/1093] d_loss: 1.34403205, g_loss: 0.58028102\n",
      "Epoch: [ 0] [ 180/1093] d_loss: 1.25369883, g_loss: 0.64316398\n",
      "Epoch: [ 0] [ 200/1093] d_loss: 1.29723299, g_loss: 0.65255749\n",
      "save down\n",
      "Epoch: [ 0] [ 220/1093] d_loss: 1.29197383, g_loss: 0.64055061\n",
      "Epoch: [ 0] [ 240/1093] d_loss: 1.26878023, g_loss: 0.65366888\n",
      "Epoch: [ 0] [ 260/1093] d_loss: 1.31012058, g_loss: 0.64424610\n",
      "Epoch: [ 0] [ 280/1093] d_loss: 1.31362200, g_loss: 0.59152973\n",
      "Epoch: [ 0] [ 300/1093] d_loss: 1.33941889, g_loss: 0.64494371\n",
      "save down\n",
      "Epoch: [ 0] [ 320/1093] d_loss: 1.35916400, g_loss: 0.60795689\n",
      "Epoch: [ 0] [ 340/1093] d_loss: 1.35818291, g_loss: 0.65233368\n",
      "Epoch: [ 0] [ 360/1093] d_loss: 1.35223532, g_loss: 0.65425807\n",
      "Epoch: [ 0] [ 380/1093] d_loss: 1.31976604, g_loss: 0.69712126\n",
      "Epoch: [ 0] [ 400/1093] d_loss: 1.34431684, g_loss: 0.61824393\n",
      "save down\n",
      "Epoch: [ 0] [ 420/1093] d_loss: 1.34039235, g_loss: 0.63122392\n",
      "Epoch: [ 0] [ 440/1093] d_loss: 1.30172694, g_loss: 0.65629721\n",
      "Epoch: [ 0] [ 460/1093] d_loss: 1.35528123, g_loss: 0.60994315\n",
      "Epoch: [ 0] [ 480/1093] d_loss: 1.32070398, g_loss: 0.66362536\n",
      "Epoch: [ 0] [ 500/1093] d_loss: 1.33892715, g_loss: 0.65986693\n",
      "save down\n",
      "Epoch: [ 0] [ 520/1093] d_loss: 1.33217323, g_loss: 0.66852975\n",
      "Epoch: [ 0] [ 540/1093] d_loss: 1.38969183, g_loss: 0.61802745\n",
      "Epoch: [ 0] [ 560/1093] d_loss: 1.34049308, g_loss: 0.63767380\n",
      "Epoch: [ 0] [ 580/1093] d_loss: 1.34190273, g_loss: 0.61228245\n",
      "Epoch: [ 0] [ 600/1093] d_loss: 1.31294441, g_loss: 0.64230847\n",
      "save down\n",
      "Epoch: [ 0] [ 620/1093] d_loss: 1.36304593, g_loss: 0.59153068\n",
      "Epoch: [ 0] [ 640/1093] d_loss: 1.36921024, g_loss: 0.62936908\n",
      "Epoch: [ 0] [ 660/1093] d_loss: 1.31752872, g_loss: 0.65144324\n",
      "Epoch: [ 0] [ 680/1093] d_loss: 1.35904205, g_loss: 0.62478459\n",
      "Epoch: [ 0] [ 700/1093] d_loss: 1.33857965, g_loss: 0.63872313\n",
      "save down\n",
      "Epoch: [ 0] [ 720/1093] d_loss: 1.37380862, g_loss: 0.66950893\n",
      "Epoch: [ 0] [ 740/1093] d_loss: 1.36681306, g_loss: 0.65868425\n",
      "Epoch: [ 0] [ 760/1093] d_loss: 1.37718916, g_loss: 0.61029184\n",
      "Epoch: [ 0] [ 780/1093] d_loss: 1.40118742, g_loss: 0.60939479\n",
      "Epoch: [ 0] [ 800/1093] d_loss: 1.37668383, g_loss: 0.64347565\n",
      "save down\n",
      "Epoch: [ 0] [ 820/1093] d_loss: 1.35147655, g_loss: 0.61392725\n",
      "Epoch: [ 0] [ 840/1093] d_loss: 1.38630617, g_loss: 0.65288055\n",
      "Epoch: [ 0] [ 860/1093] d_loss: 1.41477680, g_loss: 0.59982216\n",
      "Epoch: [ 0] [ 880/1093] d_loss: 1.34429598, g_loss: 0.64225560\n",
      "Epoch: [ 0] [ 900/1093] d_loss: 1.30106425, g_loss: 0.68863225\n",
      "save down\n",
      "Epoch: [ 0] [ 920/1093] d_loss: 1.39517546, g_loss: 0.60335755\n",
      "Epoch: [ 0] [ 940/1093] d_loss: 1.39013648, g_loss: 0.60934305\n",
      "Epoch: [ 0] [ 960/1093] d_loss: 1.40825641, g_loss: 0.61776501\n",
      "Epoch: [ 0] [ 980/1093] d_loss: 1.38468218, g_loss: 0.62475181\n",
      "Epoch: [ 0] [1000/1093] d_loss: 1.38338184, g_loss: 0.62804270\n",
      "save down\n",
      "Epoch: [ 0] [1020/1093] d_loss: 1.33834350, g_loss: 0.64543879\n",
      "Epoch: [ 0] [1040/1093] d_loss: 1.40207720, g_loss: 0.63094556\n",
      "Epoch: [ 0] [1060/1093] d_loss: 1.34487140, g_loss: 0.62240815\n",
      "Epoch: [ 0] [1080/1093] d_loss: 1.37484634, g_loss: 0.63368821\n",
      "Epoch: [ 1] [   0/1093] d_loss: 1.39984500, g_loss: 0.63751644\n",
      "save down\n",
      "Epoch: [ 1] [  20/1093] d_loss: 1.42377138, g_loss: 0.63091266\n",
      "Epoch: [ 1] [  40/1093] d_loss: 1.38307738, g_loss: 0.63708645\n",
      "Epoch: [ 1] [  60/1093] d_loss: 1.35517228, g_loss: 0.66714329\n",
      "Epoch: [ 1] [  80/1093] d_loss: 1.39674735, g_loss: 0.60813600\n",
      "Epoch: [ 1] [ 100/1093] d_loss: 1.39222157, g_loss: 0.63284427\n",
      "save down\n",
      "Epoch: [ 1] [ 120/1093] d_loss: 1.40565073, g_loss: 0.63321495\n",
      "Epoch: [ 1] [ 140/1093] d_loss: 1.44180703, g_loss: 0.58531690\n",
      "Epoch: [ 1] [ 160/1093] d_loss: 1.38721323, g_loss: 0.62172091\n",
      "Epoch: [ 1] [ 180/1093] d_loss: 1.35706496, g_loss: 0.67115957\n",
      "Epoch: [ 1] [ 200/1093] d_loss: 1.39457262, g_loss: 0.62427264\n",
      "save down\n",
      "Epoch: [ 1] [ 220/1093] d_loss: 1.37354386, g_loss: 0.64011186\n",
      "Epoch: [ 1] [ 240/1093] d_loss: 1.38758636, g_loss: 0.62737918\n",
      "Epoch: [ 1] [ 260/1093] d_loss: 1.38569021, g_loss: 0.63741702\n",
      "Epoch: [ 1] [ 280/1093] d_loss: 1.35061240, g_loss: 0.63647884\n",
      "Epoch: [ 1] [ 300/1093] d_loss: 1.36957836, g_loss: 0.65142334\n",
      "save down\n",
      "Epoch: [ 1] [ 320/1093] d_loss: 1.36432791, g_loss: 0.64604157\n",
      "Epoch: [ 1] [ 340/1093] d_loss: 1.34928286, g_loss: 0.66881013\n",
      "Epoch: [ 1] [ 360/1093] d_loss: 1.40777028, g_loss: 0.61932123\n",
      "Epoch: [ 1] [ 380/1093] d_loss: 1.32766366, g_loss: 0.63022190\n",
      "Epoch: [ 1] [ 400/1093] d_loss: 1.39006031, g_loss: 0.62449878\n",
      "save down\n",
      "Epoch: [ 1] [ 420/1093] d_loss: 1.33353591, g_loss: 0.65622413\n",
      "Epoch: [ 1] [ 440/1093] d_loss: 1.34765315, g_loss: 0.67329276\n",
      "Epoch: [ 1] [ 460/1093] d_loss: 1.39419603, g_loss: 0.60748529\n",
      "Epoch: [ 1] [ 480/1093] d_loss: 1.39228106, g_loss: 0.63880426\n",
      "Epoch: [ 1] [ 500/1093] d_loss: 1.34657931, g_loss: 0.65151453\n",
      "save down\n",
      "Epoch: [ 1] [ 520/1093] d_loss: 1.32839715, g_loss: 0.63597661\n",
      "Epoch: [ 1] [ 540/1093] d_loss: 1.40958965, g_loss: 0.63047326\n",
      "Epoch: [ 1] [ 560/1093] d_loss: 1.35960031, g_loss: 0.64799589\n",
      "Epoch: [ 1] [ 580/1093] d_loss: 1.39146411, g_loss: 0.60635734\n",
      "Epoch: [ 1] [ 600/1093] d_loss: 1.34239101, g_loss: 0.64289320\n",
      "save down\n",
      "Epoch: [ 1] [ 620/1093] d_loss: 1.38257968, g_loss: 0.61312157\n",
      "Epoch: [ 1] [ 640/1093] d_loss: 1.37814462, g_loss: 0.61843491\n",
      "Epoch: [ 1] [ 660/1093] d_loss: 1.35931671, g_loss: 0.63301075\n",
      "Epoch: [ 1] [ 680/1093] d_loss: 1.37699890, g_loss: 0.64448386\n",
      "Epoch: [ 1] [ 700/1093] d_loss: 1.38898873, g_loss: 0.61527222\n",
      "save down\n",
      "Epoch: [ 1] [ 720/1093] d_loss: 1.37146258, g_loss: 0.63121259\n",
      "Epoch: [ 1] [ 740/1093] d_loss: 1.40683675, g_loss: 0.64365494\n",
      "Epoch: [ 1] [ 760/1093] d_loss: 1.37169766, g_loss: 0.63478160\n",
      "Epoch: [ 1] [ 780/1093] d_loss: 1.39231491, g_loss: 0.60205150\n",
      "Epoch: [ 1] [ 800/1093] d_loss: 1.34090459, g_loss: 0.65086210\n",
      "save down\n",
      "Epoch: [ 1] [ 820/1093] d_loss: 1.37848186, g_loss: 0.61698914\n",
      "Epoch: [ 1] [ 840/1093] d_loss: 1.38003659, g_loss: 0.64671302\n",
      "Epoch: [ 1] [ 860/1093] d_loss: 1.39108205, g_loss: 0.64217353\n",
      "Epoch: [ 1] [ 880/1093] d_loss: 1.37528682, g_loss: 0.62481737\n",
      "Epoch: [ 1] [ 900/1093] d_loss: 1.34440100, g_loss: 0.65508258\n",
      "save down\n",
      "Epoch: [ 1] [ 920/1093] d_loss: 1.34048259, g_loss: 0.64578688\n",
      "Epoch: [ 1] [ 940/1093] d_loss: 1.38671565, g_loss: 0.62722051\n",
      "Epoch: [ 1] [ 960/1093] d_loss: 1.37384021, g_loss: 0.64592409\n",
      "Epoch: [ 1] [ 980/1093] d_loss: 1.36049175, g_loss: 0.64596111\n",
      "Epoch: [ 1] [1000/1093] d_loss: 1.37750340, g_loss: 0.62861919\n",
      "save down\n",
      "Epoch: [ 1] [1020/1093] d_loss: 1.35965979, g_loss: 0.62445647\n",
      "Epoch: [ 1] [1040/1093] d_loss: 1.36707807, g_loss: 0.64842236\n",
      "Epoch: [ 1] [1060/1093] d_loss: 1.33088291, g_loss: 0.66327745\n",
      "Epoch: [ 1] [1080/1093] d_loss: 1.37814271, g_loss: 0.62592542\n",
      "Epoch: [ 2] [   0/1093] d_loss: 1.39968443, g_loss: 0.62943166\n",
      "save down\n",
      "Epoch: [ 2] [  20/1093] d_loss: 1.36085761, g_loss: 0.64432806\n",
      "Epoch: [ 2] [  40/1093] d_loss: 1.37451863, g_loss: 0.65672088\n",
      "Epoch: [ 2] [  60/1093] d_loss: 1.33636701, g_loss: 0.65371954\n",
      "Epoch: [ 2] [  80/1093] d_loss: 1.40645730, g_loss: 0.64666659\n",
      "Epoch: [ 2] [ 100/1093] d_loss: 1.40745628, g_loss: 0.62794924\n",
      "save down\n",
      "Epoch: [ 2] [ 120/1093] d_loss: 1.37772274, g_loss: 0.61796010\n",
      "Epoch: [ 2] [ 140/1093] d_loss: 1.38958585, g_loss: 0.62164760\n",
      "Epoch: [ 2] [ 160/1093] d_loss: 1.35389280, g_loss: 0.64053798\n",
      "Epoch: [ 2] [ 180/1093] d_loss: 1.41792178, g_loss: 0.63892388\n",
      "Epoch: [ 2] [ 200/1093] d_loss: 1.37887669, g_loss: 0.63257694\n",
      "save down\n",
      "Epoch: [ 2] [ 220/1093] d_loss: 1.34764767, g_loss: 0.65258700\n",
      "Epoch: [ 2] [ 240/1093] d_loss: 1.33433175, g_loss: 0.62449074\n",
      "Epoch: [ 2] [ 260/1093] d_loss: 1.40592360, g_loss: 0.60889041\n",
      "Epoch: [ 2] [ 280/1093] d_loss: 1.31681681, g_loss: 0.65709645\n",
      "Epoch: [ 2] [ 300/1093] d_loss: 1.34159470, g_loss: 0.63977432\n",
      "save down\n",
      "Epoch: [ 2] [ 320/1093] d_loss: 1.39984429, g_loss: 0.60368180\n",
      "Epoch: [ 2] [ 340/1093] d_loss: 1.36412978, g_loss: 0.61799049\n",
      "Epoch: [ 2] [ 360/1093] d_loss: 1.38494551, g_loss: 0.62888724\n",
      "Epoch: [ 2] [ 380/1093] d_loss: 1.32655716, g_loss: 0.63881433\n",
      "Epoch: [ 2] [ 400/1093] d_loss: 1.39259160, g_loss: 0.61285901\n",
      "save down\n",
      "Epoch: [ 2] [ 420/1093] d_loss: 1.31560433, g_loss: 0.66728294\n",
      "Epoch: [ 2] [ 440/1093] d_loss: 1.35707331, g_loss: 0.60773563\n",
      "Epoch: [ 2] [ 460/1093] d_loss: 1.39070797, g_loss: 0.61053920\n",
      "Epoch: [ 2] [ 480/1093] d_loss: 1.46268415, g_loss: 0.57928216\n",
      "Epoch: [ 2] [ 500/1093] d_loss: 1.37074947, g_loss: 0.66454023\n",
      "save down\n",
      "Epoch: [ 2] [ 520/1093] d_loss: 1.31252885, g_loss: 0.64813125\n",
      "Epoch: [ 2] [ 540/1093] d_loss: 1.43005264, g_loss: 0.60358238\n",
      "Epoch: [ 2] [ 560/1093] d_loss: 1.38000083, g_loss: 0.62217951\n",
      "Epoch: [ 2] [ 580/1093] d_loss: 1.37087035, g_loss: 0.61934918\n",
      "Epoch: [ 2] [ 600/1093] d_loss: 1.35506868, g_loss: 0.62387657\n",
      "save down\n",
      "Epoch: [ 2] [ 620/1093] d_loss: 1.36483192, g_loss: 0.61515343\n",
      "Epoch: [ 2] [ 640/1093] d_loss: 1.30760455, g_loss: 0.66924846\n",
      "Epoch: [ 2] [ 660/1093] d_loss: 1.39732409, g_loss: 0.62888366\n",
      "Epoch: [ 2] [ 680/1093] d_loss: 1.34763980, g_loss: 0.63914180\n",
      "Epoch: [ 2] [ 700/1093] d_loss: 1.35923505, g_loss: 0.62179714\n",
      "save down\n",
      "Epoch: [ 2] [ 720/1093] d_loss: 1.37810516, g_loss: 0.62471497\n",
      "Epoch: [ 2] [ 740/1093] d_loss: 1.39184475, g_loss: 0.61347950\n",
      "Epoch: [ 2] [ 760/1093] d_loss: 1.37534404, g_loss: 0.61195076\n",
      "Epoch: [ 2] [ 780/1093] d_loss: 1.35609579, g_loss: 0.65294182\n",
      "Epoch: [ 2] [ 800/1093] d_loss: 1.35722554, g_loss: 0.62817705\n",
      "save down\n",
      "Epoch: [ 2] [ 820/1093] d_loss: 1.32668173, g_loss: 0.65824795\n",
      "Epoch: [ 2] [ 840/1093] d_loss: 1.36367893, g_loss: 0.64015746\n",
      "Epoch: [ 2] [ 860/1093] d_loss: 1.38790917, g_loss: 0.63455212\n",
      "Epoch: [ 2] [ 880/1093] d_loss: 1.34194291, g_loss: 0.65281296\n",
      "Epoch: [ 2] [ 900/1093] d_loss: 1.36182082, g_loss: 0.65584707\n",
      "save down\n",
      "Epoch: [ 2] [ 920/1093] d_loss: 1.35302281, g_loss: 0.63024282\n",
      "Epoch: [ 2] [ 940/1093] d_loss: 1.37421227, g_loss: 0.60717106\n",
      "Epoch: [ 2] [ 960/1093] d_loss: 1.38633633, g_loss: 0.62243170\n",
      "Epoch: [ 2] [ 980/1093] d_loss: 1.39351749, g_loss: 0.61823130\n",
      "Epoch: [ 2] [1000/1093] d_loss: 1.31854737, g_loss: 0.66421652\n",
      "save down\n",
      "Epoch: [ 2] [1020/1093] d_loss: 1.36816812, g_loss: 0.61280411\n",
      "Epoch: [ 2] [1040/1093] d_loss: 1.37308371, g_loss: 0.61016393\n",
      "Epoch: [ 2] [1060/1093] d_loss: 1.34785032, g_loss: 0.62133038\n",
      "Epoch: [ 2] [1080/1093] d_loss: 1.34730482, g_loss: 0.63496488\n",
      "Epoch: [ 3] [   0/1093] d_loss: 1.39734399, g_loss: 0.61086577\n",
      "save down\n",
      "Epoch: [ 3] [  20/1093] d_loss: 1.42408252, g_loss: 0.62786692\n",
      "Epoch: [ 3] [  40/1093] d_loss: 1.36816454, g_loss: 0.63379323\n",
      "Epoch: [ 3] [  60/1093] d_loss: 1.36701024, g_loss: 0.62485647\n",
      "Epoch: [ 3] [  80/1093] d_loss: 1.37538123, g_loss: 0.64982289\n",
      "Epoch: [ 3] [ 100/1093] d_loss: 1.35495937, g_loss: 0.64567661\n",
      "save down\n",
      "Epoch: [ 3] [ 120/1093] d_loss: 1.37349570, g_loss: 0.64201725\n",
      "Epoch: [ 3] [ 140/1093] d_loss: 1.37249541, g_loss: 0.61024541\n",
      "Epoch: [ 3] [ 160/1093] d_loss: 1.31164241, g_loss: 0.65955395\n",
      "Epoch: [ 3] [ 180/1093] d_loss: 1.40328074, g_loss: 0.63351917\n",
      "Epoch: [ 3] [ 200/1093] d_loss: 1.36944652, g_loss: 0.61847752\n",
      "save down\n",
      "Epoch: [ 3] [ 220/1093] d_loss: 1.37468541, g_loss: 0.62778389\n",
      "Epoch: [ 3] [ 240/1093] d_loss: 1.34828484, g_loss: 0.62893754\n",
      "Epoch: [ 3] [ 260/1093] d_loss: 1.38857627, g_loss: 0.61574769\n",
      "Epoch: [ 3] [ 280/1093] d_loss: 1.37151766, g_loss: 0.59296346\n",
      "Epoch: [ 3] [ 300/1093] d_loss: 1.32279646, g_loss: 0.64861786\n",
      "save down\n",
      "Epoch: [ 3] [ 320/1093] d_loss: 1.38971305, g_loss: 0.60405529\n",
      "Epoch: [ 3] [ 340/1093] d_loss: 1.31907916, g_loss: 0.63889539\n",
      "Epoch: [ 3] [ 360/1093] d_loss: 1.38068175, g_loss: 0.60635412\n",
      "Epoch: [ 3] [ 380/1093] d_loss: 1.33743525, g_loss: 0.61095107\n",
      "Epoch: [ 3] [ 400/1093] d_loss: 1.36474311, g_loss: 0.61614764\n",
      "save down\n",
      "Epoch: [ 3] [ 420/1093] d_loss: 1.33848047, g_loss: 0.64222068\n",
      "Epoch: [ 3] [ 440/1093] d_loss: 1.36134458, g_loss: 0.63903344\n",
      "Epoch: [ 3] [ 460/1093] d_loss: 1.35254920, g_loss: 0.63676083\n",
      "Epoch: [ 3] [ 480/1093] d_loss: 1.39802384, g_loss: 0.60127348\n",
      "Epoch: [ 3] [ 500/1093] d_loss: 1.34469724, g_loss: 0.64358884\n",
      "save down\n",
      "Epoch: [ 3] [ 520/1093] d_loss: 1.32831430, g_loss: 0.62469661\n",
      "Epoch: [ 3] [ 540/1093] d_loss: 1.33547688, g_loss: 0.65448010\n",
      "Epoch: [ 3] [ 560/1093] d_loss: 1.37867022, g_loss: 0.62145138\n",
      "Epoch: [ 3] [ 580/1093] d_loss: 1.38146758, g_loss: 0.60597277\n",
      "Epoch: [ 3] [ 600/1093] d_loss: 1.33776140, g_loss: 0.61510289\n",
      "save down\n",
      "Epoch: [ 3] [ 620/1093] d_loss: 1.30448949, g_loss: 0.64135492\n",
      "Epoch: [ 3] [ 640/1093] d_loss: 1.35379767, g_loss: 0.62590271\n",
      "Epoch: [ 3] [ 660/1093] d_loss: 1.36295748, g_loss: 0.64744103\n",
      "Epoch: [ 3] [ 680/1093] d_loss: 1.35449934, g_loss: 0.63929832\n",
      "Epoch: [ 3] [ 700/1093] d_loss: 1.33988094, g_loss: 0.62801290\n",
      "save down\n",
      "Epoch: [ 3] [ 720/1093] d_loss: 1.37319541, g_loss: 0.62755454\n",
      "Epoch: [ 3] [ 740/1093] d_loss: 1.37760746, g_loss: 0.61875093\n",
      "Epoch: [ 3] [ 760/1093] d_loss: 1.38836765, g_loss: 0.61656380\n",
      "Epoch: [ 3] [ 780/1093] d_loss: 1.34243989, g_loss: 0.63204044\n",
      "Epoch: [ 3] [ 800/1093] d_loss: 1.35534155, g_loss: 0.65598685\n",
      "save down\n",
      "Epoch: [ 3] [ 820/1093] d_loss: 1.38467050, g_loss: 0.60999531\n",
      "Epoch: [ 3] [ 840/1093] d_loss: 1.36149979, g_loss: 0.62822449\n",
      "Epoch: [ 3] [ 860/1093] d_loss: 1.38538718, g_loss: 0.62843513\n",
      "Epoch: [ 3] [ 880/1093] d_loss: 1.31995630, g_loss: 0.66869491\n",
      "Epoch: [ 3] [ 900/1093] d_loss: 1.36954069, g_loss: 0.63150370\n",
      "save down\n",
      "Epoch: [ 3] [ 920/1093] d_loss: 1.33993697, g_loss: 0.62455750\n",
      "Epoch: [ 3] [ 940/1093] d_loss: 1.38856208, g_loss: 0.62812102\n",
      "Epoch: [ 3] [ 960/1093] d_loss: 1.36757803, g_loss: 0.65587449\n",
      "Epoch: [ 3] [ 980/1093] d_loss: 1.35869622, g_loss: 0.66403735\n",
      "Epoch: [ 3] [1000/1093] d_loss: 1.29232812, g_loss: 0.66295862\n",
      "save down\n",
      "Epoch: [ 3] [1020/1093] d_loss: 1.32974601, g_loss: 0.63538462\n",
      "Epoch: [ 3] [1040/1093] d_loss: 1.37846243, g_loss: 0.61601835\n",
      "Epoch: [ 3] [1060/1093] d_loss: 1.36779034, g_loss: 0.61911857\n",
      "Epoch: [ 3] [1080/1093] d_loss: 1.38092518, g_loss: 0.60343522\n",
      "Epoch: [ 4] [   0/1093] d_loss: 1.36822724, g_loss: 0.61902368\n",
      "save down\n",
      "Epoch: [ 4] [  20/1093] d_loss: 1.39288831, g_loss: 0.61582404\n",
      "Epoch: [ 4] [  40/1093] d_loss: 1.41636562, g_loss: 0.58483988\n",
      "Epoch: [ 4] [  60/1093] d_loss: 1.30762994, g_loss: 0.65862858\n",
      "Epoch: [ 4] [  80/1093] d_loss: 1.39124537, g_loss: 0.64152861\n",
      "Epoch: [ 4] [ 100/1093] d_loss: 1.32889593, g_loss: 0.65294635\n",
      "save down\n",
      "Epoch: [ 4] [ 120/1093] d_loss: 1.36978030, g_loss: 0.63182986\n",
      "Epoch: [ 4] [ 140/1093] d_loss: 1.35810339, g_loss: 0.64230466\n",
      "Epoch: [ 4] [ 160/1093] d_loss: 1.34077811, g_loss: 0.62002063\n",
      "Epoch: [ 4] [ 180/1093] d_loss: 1.36159492, g_loss: 0.63882536\n",
      "Epoch: [ 4] [ 200/1093] d_loss: 1.32316494, g_loss: 0.65112555\n",
      "save down\n",
      "Epoch: [ 4] [ 220/1093] d_loss: 1.39934754, g_loss: 0.62124717\n",
      "Epoch: [ 4] [ 240/1093] d_loss: 1.30497003, g_loss: 0.61777091\n",
      "Epoch: [ 4] [ 260/1093] d_loss: 1.40146494, g_loss: 0.60888195\n",
      "Epoch: [ 4] [ 280/1093] d_loss: 1.32528901, g_loss: 0.63642359\n",
      "Epoch: [ 4] [ 300/1093] d_loss: 1.35281885, g_loss: 0.61004144\n",
      "save down\n",
      "Epoch: [ 4] [ 320/1093] d_loss: 1.36167216, g_loss: 0.63327801\n",
      "Epoch: [ 4] [ 340/1093] d_loss: 1.37984133, g_loss: 0.59812605\n",
      "Epoch: [ 4] [ 360/1093] d_loss: 1.35906816, g_loss: 0.62260044\n",
      "Epoch: [ 4] [ 380/1093] d_loss: 1.32576609, g_loss: 0.62495154\n",
      "Epoch: [ 4] [ 400/1093] d_loss: 1.35644770, g_loss: 0.61304033\n",
      "save down\n",
      "Epoch: [ 4] [ 420/1093] d_loss: 1.37572110, g_loss: 0.62586671\n",
      "Epoch: [ 4] [ 440/1093] d_loss: 1.32958770, g_loss: 0.64101404\n",
      "Epoch: [ 4] [ 460/1093] d_loss: 1.32788634, g_loss: 0.64087915\n",
      "Epoch: [ 4] [ 480/1093] d_loss: 1.36384547, g_loss: 0.64218116\n",
      "Epoch: [ 4] [ 500/1093] d_loss: 1.33996034, g_loss: 0.65920544\n",
      "save down\n",
      "Epoch: [ 4] [ 520/1093] d_loss: 1.30742526, g_loss: 0.63215351\n",
      "Epoch: [ 4] [ 540/1093] d_loss: 1.32016444, g_loss: 0.64207041\n",
      "Epoch: [ 4] [ 560/1093] d_loss: 1.30601013, g_loss: 0.65379184\n",
      "Epoch: [ 4] [ 580/1093] d_loss: 1.33783102, g_loss: 0.61996567\n",
      "Epoch: [ 4] [ 600/1093] d_loss: 1.32470751, g_loss: 0.63773388\n",
      "save down\n",
      "Epoch: [ 4] [ 620/1093] d_loss: 1.36240542, g_loss: 0.60597461\n",
      "Epoch: [ 4] [ 640/1093] d_loss: 1.36117172, g_loss: 0.63663256\n",
      "Epoch: [ 4] [ 660/1093] d_loss: 1.38177824, g_loss: 0.62214750\n",
      "Epoch: [ 4] [ 680/1093] d_loss: 1.38250351, g_loss: 0.59767163\n",
      "Epoch: [ 4] [ 700/1093] d_loss: 1.32964230, g_loss: 0.61597759\n",
      "save down\n",
      "Epoch: [ 4] [ 720/1093] d_loss: 1.34012496, g_loss: 0.61468005\n",
      "Epoch: [ 4] [ 740/1093] d_loss: 1.34397793, g_loss: 0.63164973\n",
      "Epoch: [ 4] [ 760/1093] d_loss: 1.32633233, g_loss: 0.63391352\n",
      "Epoch: [ 4] [ 780/1093] d_loss: 1.30311930, g_loss: 0.62147492\n",
      "Epoch: [ 4] [ 800/1093] d_loss: 1.34702933, g_loss: 0.65642506\n",
      "save down\n",
      "Epoch: [ 4] [ 820/1093] d_loss: 1.35423112, g_loss: 0.61002690\n",
      "Epoch: [ 4] [ 840/1093] d_loss: 1.33397603, g_loss: 0.64337051\n",
      "Epoch: [ 4] [ 860/1093] d_loss: 1.37966502, g_loss: 0.61595750\n",
      "Epoch: [ 4] [ 880/1093] d_loss: 1.28950882, g_loss: 0.67349392\n",
      "Epoch: [ 4] [ 900/1093] d_loss: 1.36778092, g_loss: 0.61601359\n",
      "save down\n",
      "Epoch: [ 4] [ 920/1093] d_loss: 1.33732963, g_loss: 0.61782885\n",
      "Epoch: [ 4] [ 940/1093] d_loss: 1.37977803, g_loss: 0.61555207\n",
      "Epoch: [ 4] [ 960/1093] d_loss: 1.35160637, g_loss: 0.62713993\n",
      "Epoch: [ 4] [ 980/1093] d_loss: 1.38004863, g_loss: 0.64174646\n",
      "Epoch: [ 4] [1000/1093] d_loss: 1.37791407, g_loss: 0.64388871\n",
      "save down\n",
      "Epoch: [ 4] [1020/1093] d_loss: 1.37686384, g_loss: 0.61616457\n",
      "Epoch: [ 4] [1040/1093] d_loss: 1.32638669, g_loss: 0.62677044\n",
      "Epoch: [ 4] [1060/1093] d_loss: 1.31080866, g_loss: 0.62070233\n",
      "Epoch: [ 4] [1080/1093] d_loss: 1.35445666, g_loss: 0.63080925\n",
      "Epoch: [ 5] [   0/1093] d_loss: 1.37833047, g_loss: 0.61238253\n",
      "save down\n",
      "Epoch: [ 5] [  20/1093] d_loss: 1.38419616, g_loss: 0.61709356\n",
      "Epoch: [ 5] [  40/1093] d_loss: 1.38893485, g_loss: 0.61827379\n",
      "Epoch: [ 5] [  60/1093] d_loss: 1.33229363, g_loss: 0.63757169\n",
      "Epoch: [ 5] [  80/1093] d_loss: 1.37945747, g_loss: 0.64097303\n",
      "Epoch: [ 5] [ 100/1093] d_loss: 1.32877707, g_loss: 0.66642803\n",
      "save down\n",
      "Epoch: [ 5] [ 120/1093] d_loss: 1.39974427, g_loss: 0.62391728\n",
      "Epoch: [ 5] [ 140/1093] d_loss: 1.32166278, g_loss: 0.62634957\n",
      "Epoch: [ 5] [ 160/1093] d_loss: 1.30879259, g_loss: 0.65202922\n",
      "Epoch: [ 5] [ 180/1093] d_loss: 1.32939076, g_loss: 0.63499236\n",
      "Epoch: [ 5] [ 200/1093] d_loss: 1.31612194, g_loss: 0.65136337\n",
      "save down\n",
      "Epoch: [ 5] [ 220/1093] d_loss: 1.35386300, g_loss: 0.64478767\n",
      "Epoch: [ 5] [ 240/1093] d_loss: 1.30883718, g_loss: 0.62985551\n",
      "Epoch: [ 5] [ 260/1093] d_loss: 1.37271357, g_loss: 0.62641203\n",
      "Epoch: [ 5] [ 280/1093] d_loss: 1.35854650, g_loss: 0.61455905\n",
      "Epoch: [ 5] [ 300/1093] d_loss: 1.35271466, g_loss: 0.61139560\n",
      "save down\n",
      "Epoch: [ 5] [ 320/1093] d_loss: 1.32264352, g_loss: 0.65167671\n",
      "Epoch: [ 5] [ 340/1093] d_loss: 1.30827260, g_loss: 0.63323790\n",
      "Epoch: [ 5] [ 360/1093] d_loss: 1.39201617, g_loss: 0.59234542\n",
      "Epoch: [ 5] [ 380/1093] d_loss: 1.31635356, g_loss: 0.63637459\n",
      "Epoch: [ 5] [ 400/1093] d_loss: 1.33494163, g_loss: 0.60411394\n",
      "save down\n",
      "Epoch: [ 5] [ 420/1093] d_loss: 1.34291184, g_loss: 0.62320077\n",
      "Epoch: [ 5] [ 440/1093] d_loss: 1.27969408, g_loss: 0.66393697\n",
      "Epoch: [ 5] [ 460/1093] d_loss: 1.36414790, g_loss: 0.61121976\n",
      "Epoch: [ 5] [ 480/1093] d_loss: 1.38352251, g_loss: 0.62892222\n",
      "Epoch: [ 5] [ 500/1093] d_loss: 1.32327282, g_loss: 0.66555381\n",
      "save down\n",
      "Epoch: [ 5] [ 520/1093] d_loss: 1.32708812, g_loss: 0.64807940\n",
      "Epoch: [ 5] [ 540/1093] d_loss: 1.36203146, g_loss: 0.60100615\n",
      "Epoch: [ 5] [ 560/1093] d_loss: 1.34005523, g_loss: 0.61448961\n",
      "Epoch: [ 5] [ 580/1093] d_loss: 1.31915379, g_loss: 0.62120664\n",
      "Epoch: [ 5] [ 600/1093] d_loss: 1.32552624, g_loss: 0.60069585\n",
      "save down\n",
      "Epoch: [ 5] [ 620/1093] d_loss: 1.30032802, g_loss: 0.64158297\n",
      "Epoch: [ 5] [ 640/1093] d_loss: 1.34500062, g_loss: 0.63901651\n",
      "Epoch: [ 5] [ 660/1093] d_loss: 1.32963037, g_loss: 0.62673569\n",
      "Epoch: [ 5] [ 680/1093] d_loss: 1.29829073, g_loss: 0.65104902\n",
      "Epoch: [ 5] [ 700/1093] d_loss: 1.29054832, g_loss: 0.66065824\n",
      "save down\n",
      "Epoch: [ 5] [ 720/1093] d_loss: 1.33252549, g_loss: 0.61704981\n",
      "Epoch: [ 5] [ 740/1093] d_loss: 1.28297591, g_loss: 0.66994363\n",
      "Epoch: [ 5] [ 760/1093] d_loss: 1.35722280, g_loss: 0.63314342\n",
      "Epoch: [ 5] [ 780/1093] d_loss: 1.34085917, g_loss: 0.61969566\n",
      "Epoch: [ 5] [ 800/1093] d_loss: 1.36445594, g_loss: 0.60804558\n",
      "save down\n",
      "Epoch: [ 5] [ 820/1093] d_loss: 1.34915400, g_loss: 0.60473216\n",
      "Epoch: [ 5] [ 840/1093] d_loss: 1.30141509, g_loss: 0.65502870\n",
      "Epoch: [ 5] [ 860/1093] d_loss: 1.37566411, g_loss: 0.61629748\n",
      "Epoch: [ 5] [ 880/1093] d_loss: 1.30193138, g_loss: 0.64546084\n",
      "Epoch: [ 5] [ 900/1093] d_loss: 1.36000586, g_loss: 0.58655536\n",
      "save down\n",
      "Epoch: [ 5] [ 920/1093] d_loss: 1.33627319, g_loss: 0.67456412\n",
      "Epoch: [ 5] [ 940/1093] d_loss: 1.35990906, g_loss: 0.61683744\n",
      "Epoch: [ 5] [ 960/1093] d_loss: 1.28323007, g_loss: 0.64637893\n",
      "Epoch: [ 5] [ 980/1093] d_loss: 1.35484588, g_loss: 0.62477320\n",
      "Epoch: [ 5] [1000/1093] d_loss: 1.27761602, g_loss: 0.65537953\n",
      "save down\n",
      "Epoch: [ 5] [1020/1093] d_loss: 1.31547093, g_loss: 0.63512546\n",
      "Epoch: [ 5] [1040/1093] d_loss: 1.32902122, g_loss: 0.61392504\n",
      "Epoch: [ 5] [1060/1093] d_loss: 1.28126121, g_loss: 0.65695798\n",
      "Epoch: [ 5] [1080/1093] d_loss: 1.31464219, g_loss: 0.65588093\n",
      "Epoch: [ 6] [   0/1093] d_loss: 1.36100245, g_loss: 0.63110191\n",
      "save down\n",
      "Epoch: [ 6] [  20/1093] d_loss: 1.30519390, g_loss: 0.66391915\n",
      "Epoch: [ 6] [  40/1093] d_loss: 1.38298881, g_loss: 0.61774766\n",
      "Epoch: [ 6] [  60/1093] d_loss: 1.32925272, g_loss: 0.65795100\n",
      "Epoch: [ 6] [  80/1093] d_loss: 1.37957668, g_loss: 0.60612768\n",
      "Epoch: [ 6] [ 100/1093] d_loss: 1.33523929, g_loss: 0.62035549\n",
      "save down\n",
      "Epoch: [ 6] [ 120/1093] d_loss: 1.33970189, g_loss: 0.62511480\n",
      "Epoch: [ 6] [ 140/1093] d_loss: 1.35245347, g_loss: 0.61391222\n",
      "Epoch: [ 6] [ 160/1093] d_loss: 1.29102898, g_loss: 0.67429817\n",
      "Epoch: [ 6] [ 180/1093] d_loss: 1.37681830, g_loss: 0.61294192\n",
      "Epoch: [ 6] [ 200/1093] d_loss: 1.30061936, g_loss: 0.66125464\n",
      "save down\n",
      "Epoch: [ 6] [ 220/1093] d_loss: 1.35550261, g_loss: 0.62662613\n",
      "Epoch: [ 6] [ 240/1093] d_loss: 1.29518163, g_loss: 0.63183671\n",
      "Epoch: [ 6] [ 260/1093] d_loss: 1.30774760, g_loss: 0.66829926\n",
      "Epoch: [ 6] [ 280/1093] d_loss: 1.33116961, g_loss: 0.61835641\n",
      "Epoch: [ 6] [ 300/1093] d_loss: 1.37996340, g_loss: 0.58811998\n",
      "save down\n",
      "Epoch: [ 6] [ 320/1093] d_loss: 1.31106293, g_loss: 0.63310540\n",
      "Epoch: [ 6] [ 340/1093] d_loss: 1.33621812, g_loss: 0.62532687\n",
      "Epoch: [ 6] [ 360/1093] d_loss: 1.34097695, g_loss: 0.61119366\n",
      "Epoch: [ 6] [ 380/1093] d_loss: 1.33040297, g_loss: 0.65193999\n",
      "Epoch: [ 6] [ 400/1093] d_loss: 1.33678913, g_loss: 0.65727121\n",
      "save down\n",
      "Epoch: [ 6] [ 420/1093] d_loss: 1.32657051, g_loss: 0.62149417\n",
      "Epoch: [ 6] [ 440/1093] d_loss: 1.25892961, g_loss: 0.67133725\n",
      "Epoch: [ 6] [ 460/1093] d_loss: 1.31925142, g_loss: 0.63192427\n",
      "Epoch: [ 6] [ 480/1093] d_loss: 1.35212433, g_loss: 0.62395036\n",
      "Epoch: [ 6] [ 500/1093] d_loss: 1.32341111, g_loss: 0.63637257\n",
      "save down\n",
      "Epoch: [ 6] [ 520/1093] d_loss: 1.35398293, g_loss: 0.59383076\n",
      "Epoch: [ 6] [ 540/1093] d_loss: 1.33445036, g_loss: 0.63810992\n",
      "Epoch: [ 6] [ 560/1093] d_loss: 1.31209350, g_loss: 0.61935210\n",
      "Epoch: [ 6] [ 580/1093] d_loss: 1.33122075, g_loss: 0.62206972\n",
      "Epoch: [ 6] [ 600/1093] d_loss: 1.25017047, g_loss: 0.64718968\n",
      "save down\n",
      "Epoch: [ 6] [ 620/1093] d_loss: 1.28510928, g_loss: 0.63940215\n",
      "Epoch: [ 6] [ 640/1093] d_loss: 1.35757780, g_loss: 0.60079652\n",
      "Epoch: [ 6] [ 660/1093] d_loss: 1.35725033, g_loss: 0.62139875\n",
      "Epoch: [ 6] [ 680/1093] d_loss: 1.29081881, g_loss: 0.63180137\n",
      "Epoch: [ 6] [ 700/1093] d_loss: 1.29324698, g_loss: 0.63817072\n",
      "save down\n",
      "Epoch: [ 6] [ 720/1093] d_loss: 1.31748176, g_loss: 0.64524591\n",
      "Epoch: [ 6] [ 740/1093] d_loss: 1.30960441, g_loss: 0.63631207\n",
      "Epoch: [ 6] [ 760/1093] d_loss: 1.40825987, g_loss: 0.58684123\n",
      "Epoch: [ 6] [ 780/1093] d_loss: 1.31847548, g_loss: 0.63284564\n",
      "Epoch: [ 6] [ 800/1093] d_loss: 1.32511067, g_loss: 0.63210654\n",
      "save down\n",
      "Epoch: [ 6] [ 820/1093] d_loss: 1.28140545, g_loss: 0.65200597\n",
      "Epoch: [ 6] [ 840/1093] d_loss: 1.30842733, g_loss: 0.63313317\n",
      "Epoch: [ 6] [ 860/1093] d_loss: 1.32012677, g_loss: 0.63655704\n",
      "Epoch: [ 6] [ 880/1093] d_loss: 1.29093885, g_loss: 0.65881336\n",
      "Epoch: [ 6] [ 900/1093] d_loss: 1.30958843, g_loss: 0.64416659\n",
      "save down\n",
      "Epoch: [ 6] [ 920/1093] d_loss: 1.30987215, g_loss: 0.61433458\n",
      "Epoch: [ 6] [ 940/1093] d_loss: 1.33742023, g_loss: 0.62466598\n",
      "Epoch: [ 6] [ 960/1093] d_loss: 1.31011248, g_loss: 0.61816382\n",
      "Epoch: [ 6] [ 980/1093] d_loss: 1.40564036, g_loss: 0.59202802\n",
      "Epoch: [ 6] [1000/1093] d_loss: 1.35530591, g_loss: 0.65324533\n",
      "save down\n",
      "Epoch: [ 6] [1020/1093] d_loss: 1.30439758, g_loss: 0.64275360\n",
      "Epoch: [ 6] [1040/1093] d_loss: 1.31938934, g_loss: 0.64988399\n",
      "Epoch: [ 6] [1060/1093] d_loss: 1.27812147, g_loss: 0.64968246\n",
      "Epoch: [ 6] [1080/1093] d_loss: 1.32806969, g_loss: 0.61594999\n",
      "Epoch: [ 7] [   0/1093] d_loss: 1.30797672, g_loss: 0.63641989\n",
      "save down\n",
      "Epoch: [ 7] [  20/1093] d_loss: 1.25719476, g_loss: 0.67738652\n",
      "Epoch: [ 7] [  40/1093] d_loss: 1.33573520, g_loss: 0.63181865\n",
      "Epoch: [ 7] [  60/1093] d_loss: 1.32340944, g_loss: 0.63350415\n",
      "Epoch: [ 7] [  80/1093] d_loss: 1.41357100, g_loss: 0.61985552\n",
      "Epoch: [ 7] [ 100/1093] d_loss: 1.33225751, g_loss: 0.61732322\n",
      "save down\n",
      "Epoch: [ 7] [ 120/1093] d_loss: 1.37674117, g_loss: 0.59275007\n",
      "Epoch: [ 7] [ 140/1093] d_loss: 1.28413129, g_loss: 0.64768481\n",
      "Epoch: [ 7] [ 160/1093] d_loss: 1.29751396, g_loss: 0.63507408\n",
      "Epoch: [ 7] [ 180/1093] d_loss: 1.32137847, g_loss: 0.64894700\n",
      "Epoch: [ 7] [ 200/1093] d_loss: 1.24512661, g_loss: 0.68147719\n",
      "save down\n",
      "Epoch: [ 7] [ 220/1093] d_loss: 1.35586452, g_loss: 0.59695303\n",
      "Epoch: [ 7] [ 240/1093] d_loss: 1.25559092, g_loss: 0.64302731\n",
      "Epoch: [ 7] [ 260/1093] d_loss: 1.34681344, g_loss: 0.66610050\n",
      "Epoch: [ 7] [ 280/1093] d_loss: 1.36497414, g_loss: 0.62365991\n",
      "Epoch: [ 7] [ 300/1093] d_loss: 1.34917760, g_loss: 0.61240822\n",
      "save down\n",
      "Epoch: [ 7] [ 320/1093] d_loss: 1.28025818, g_loss: 0.62730849\n",
      "Epoch: [ 7] [ 340/1093] d_loss: 1.31403768, g_loss: 0.61962670\n",
      "Epoch: [ 7] [ 360/1093] d_loss: 1.30171931, g_loss: 0.62623930\n",
      "Epoch: [ 7] [ 380/1093] d_loss: 1.27703810, g_loss: 0.62367916\n",
      "Epoch: [ 7] [ 400/1093] d_loss: 1.34889162, g_loss: 0.61579329\n",
      "save down\n",
      "Epoch: [ 7] [ 420/1093] d_loss: 1.32208538, g_loss: 0.61985785\n",
      "Epoch: [ 7] [ 440/1093] d_loss: 1.32208765, g_loss: 0.60678697\n",
      "Epoch: [ 7] [ 460/1093] d_loss: 1.33946252, g_loss: 0.58552420\n",
      "Epoch: [ 7] [ 480/1093] d_loss: 1.33289087, g_loss: 0.66129351\n",
      "Epoch: [ 7] [ 500/1093] d_loss: 1.26996768, g_loss: 0.64794236\n",
      "save down\n",
      "Epoch: [ 7] [ 520/1093] d_loss: 1.25018096, g_loss: 0.66567308\n",
      "Epoch: [ 7] [ 540/1093] d_loss: 1.32111216, g_loss: 0.60083812\n",
      "Epoch: [ 7] [ 560/1093] d_loss: 1.27786982, g_loss: 0.64185447\n",
      "Epoch: [ 7] [ 580/1093] d_loss: 1.21800661, g_loss: 0.68742371\n",
      "Epoch: [ 7] [ 600/1093] d_loss: 1.30526388, g_loss: 0.58956271\n",
      "save down\n",
      "Epoch: [ 7] [ 620/1093] d_loss: 1.33111000, g_loss: 0.65104645\n",
      "Epoch: [ 7] [ 640/1093] d_loss: 1.27740872, g_loss: 0.65138423\n",
      "Epoch: [ 7] [ 660/1093] d_loss: 1.34043598, g_loss: 0.62502754\n",
      "Epoch: [ 7] [ 680/1093] d_loss: 1.33435035, g_loss: 0.60503757\n",
      "Epoch: [ 7] [ 700/1093] d_loss: 1.28506136, g_loss: 0.65543914\n",
      "save down\n",
      "Epoch: [ 7] [ 720/1093] d_loss: 1.33629620, g_loss: 0.67256343\n",
      "Epoch: [ 7] [ 740/1093] d_loss: 1.35635400, g_loss: 0.59483659\n",
      "Epoch: [ 7] [ 760/1093] d_loss: 1.41801155, g_loss: 0.55009055\n",
      "Epoch: [ 7] [ 780/1093] d_loss: 1.26671910, g_loss: 0.63657004\n",
      "Epoch: [ 7] [ 800/1093] d_loss: 1.30523682, g_loss: 0.63305753\n",
      "save down\n",
      "Epoch: [ 7] [ 820/1093] d_loss: 1.32840180, g_loss: 0.62409586\n",
      "Epoch: [ 7] [ 840/1093] d_loss: 1.30141330, g_loss: 0.63319051\n",
      "Epoch: [ 7] [ 860/1093] d_loss: 1.31925654, g_loss: 0.64329255\n",
      "Epoch: [ 7] [ 880/1093] d_loss: 1.27808499, g_loss: 0.65816671\n",
      "Epoch: [ 7] [ 900/1093] d_loss: 1.35854125, g_loss: 0.59693736\n",
      "save down\n",
      "Epoch: [ 7] [ 920/1093] d_loss: 1.30785823, g_loss: 0.63075566\n",
      "Epoch: [ 7] [ 940/1093] d_loss: 1.34748602, g_loss: 0.59968567\n",
      "Epoch: [ 7] [ 960/1093] d_loss: 1.28801227, g_loss: 0.64881116\n",
      "Epoch: [ 7] [ 980/1093] d_loss: 1.32243359, g_loss: 0.64424640\n",
      "Epoch: [ 7] [1000/1093] d_loss: 1.31350172, g_loss: 0.67972296\n",
      "save down\n",
      "Epoch: [ 7] [1020/1093] d_loss: 1.35492516, g_loss: 0.59290785\n",
      "Epoch: [ 7] [1040/1093] d_loss: 1.31194079, g_loss: 0.60494691\n",
      "Epoch: [ 7] [1060/1093] d_loss: 1.33225417, g_loss: 0.62105811\n",
      "Epoch: [ 7] [1080/1093] d_loss: 1.29347217, g_loss: 0.62909168\n",
      "Epoch: [ 8] [   0/1093] d_loss: 1.34188545, g_loss: 0.62715852\n",
      "save down\n",
      "Epoch: [ 8] [  20/1093] d_loss: 1.33525515, g_loss: 0.61887234\n",
      "Epoch: [ 8] [  40/1093] d_loss: 1.37772954, g_loss: 0.60423267\n",
      "Epoch: [ 8] [  60/1093] d_loss: 1.36332095, g_loss: 0.61855686\n",
      "Epoch: [ 8] [  80/1093] d_loss: 1.31237340, g_loss: 0.63337541\n",
      "Epoch: [ 8] [ 100/1093] d_loss: 1.30318427, g_loss: 0.60728121\n",
      "save down\n",
      "Epoch: [ 8] [ 120/1093] d_loss: 1.31300783, g_loss: 0.65267366\n",
      "Epoch: [ 8] [ 140/1093] d_loss: 1.32195354, g_loss: 0.58375049\n",
      "Epoch: [ 8] [ 160/1093] d_loss: 1.34115815, g_loss: 0.61093974\n",
      "Epoch: [ 8] [ 180/1093] d_loss: 1.25260043, g_loss: 0.66836619\n",
      "Epoch: [ 8] [ 200/1093] d_loss: 1.26590824, g_loss: 0.64073050\n",
      "save down\n",
      "Epoch: [ 8] [ 220/1093] d_loss: 1.32912588, g_loss: 0.62109494\n",
      "Epoch: [ 8] [ 240/1093] d_loss: 1.22319591, g_loss: 0.65965450\n",
      "Epoch: [ 8] [ 260/1093] d_loss: 1.33296454, g_loss: 0.67114788\n",
      "Epoch: [ 8] [ 280/1093] d_loss: 1.30754375, g_loss: 0.61301333\n",
      "Epoch: [ 8] [ 300/1093] d_loss: 1.31636846, g_loss: 0.63672316\n",
      "save down\n",
      "Epoch: [ 8] [ 320/1093] d_loss: 1.22517657, g_loss: 0.70049679\n",
      "Epoch: [ 8] [ 340/1093] d_loss: 1.28486800, g_loss: 0.64087856\n",
      "Epoch: [ 8] [ 360/1093] d_loss: 1.34642315, g_loss: 0.64289397\n",
      "Epoch: [ 8] [ 380/1093] d_loss: 1.23151517, g_loss: 0.64328074\n",
      "Epoch: [ 8] [ 400/1093] d_loss: 1.35227084, g_loss: 0.62119335\n",
      "save down\n",
      "Epoch: [ 8] [ 420/1093] d_loss: 1.30935216, g_loss: 0.61704755\n",
      "Epoch: [ 8] [ 440/1093] d_loss: 1.27785277, g_loss: 0.60380894\n",
      "Epoch: [ 8] [ 460/1093] d_loss: 1.29490161, g_loss: 0.62555856\n",
      "Epoch: [ 8] [ 480/1093] d_loss: 1.31888092, g_loss: 0.62702876\n",
      "Epoch: [ 8] [ 500/1093] d_loss: 1.33914113, g_loss: 0.61497676\n",
      "save down\n",
      "Epoch: [ 8] [ 520/1093] d_loss: 1.23148441, g_loss: 0.65511024\n",
      "Epoch: [ 8] [ 540/1093] d_loss: 1.33287406, g_loss: 0.58699489\n",
      "Epoch: [ 8] [ 560/1093] d_loss: 1.29206264, g_loss: 0.61902988\n",
      "Epoch: [ 8] [ 580/1093] d_loss: 1.23865914, g_loss: 0.66103256\n",
      "Epoch: [ 8] [ 600/1093] d_loss: 1.27458727, g_loss: 0.63046128\n",
      "save down\n",
      "Epoch: [ 8] [ 620/1093] d_loss: 1.34182882, g_loss: 0.60240752\n",
      "Epoch: [ 8] [ 640/1093] d_loss: 1.32046318, g_loss: 0.60807753\n",
      "Epoch: [ 8] [ 660/1093] d_loss: 1.24536133, g_loss: 0.65343821\n",
      "Epoch: [ 8] [ 680/1093] d_loss: 1.25062037, g_loss: 0.64743769\n",
      "Epoch: [ 8] [ 700/1093] d_loss: 1.25611579, g_loss: 0.65317732\n",
      "save down\n",
      "Epoch: [ 8] [ 720/1093] d_loss: 1.25479126, g_loss: 0.67084348\n",
      "Epoch: [ 8] [ 740/1093] d_loss: 1.28135085, g_loss: 0.67921293\n",
      "Epoch: [ 8] [ 760/1093] d_loss: 1.35949397, g_loss: 0.56476200\n",
      "Epoch: [ 8] [ 780/1093] d_loss: 1.27990997, g_loss: 0.65053236\n",
      "Epoch: [ 8] [ 800/1093] d_loss: 1.27189350, g_loss: 0.62334996\n",
      "save down\n",
      "Epoch: [ 8] [ 820/1093] d_loss: 1.32782388, g_loss: 0.62069815\n",
      "Epoch: [ 8] [ 840/1093] d_loss: 1.29174674, g_loss: 0.59259039\n",
      "Epoch: [ 8] [ 860/1093] d_loss: 1.41335750, g_loss: 0.57158017\n",
      "Epoch: [ 8] [ 880/1093] d_loss: 1.31126308, g_loss: 0.64391124\n",
      "Epoch: [ 8] [ 900/1093] d_loss: 1.32473230, g_loss: 0.63246071\n",
      "save down\n",
      "Epoch: [ 8] [ 920/1093] d_loss: 1.30199623, g_loss: 0.60590649\n",
      "Epoch: [ 8] [ 940/1093] d_loss: 1.35771656, g_loss: 0.59057385\n",
      "Epoch: [ 8] [ 960/1093] d_loss: 1.25544858, g_loss: 0.64416242\n",
      "Epoch: [ 8] [ 980/1093] d_loss: 1.34312153, g_loss: 0.63179302\n",
      "Epoch: [ 8] [1000/1093] d_loss: 1.23765683, g_loss: 0.69539422\n",
      "save down\n",
      "Epoch: [ 8] [1020/1093] d_loss: 1.23917878, g_loss: 0.68004042\n",
      "Epoch: [ 8] [1040/1093] d_loss: 1.27377129, g_loss: 0.63512743\n",
      "Epoch: [ 8] [1060/1093] d_loss: 1.25425351, g_loss: 0.66626114\n",
      "Epoch: [ 8] [1080/1093] d_loss: 1.26978993, g_loss: 0.62895107\n",
      "Epoch: [ 9] [   0/1093] d_loss: 1.28091383, g_loss: 0.65089381\n",
      "save down\n",
      "Epoch: [ 9] [  20/1093] d_loss: 1.29553723, g_loss: 0.65164125\n",
      "Epoch: [ 9] [  40/1093] d_loss: 1.36779952, g_loss: 0.63749367\n",
      "Epoch: [ 9] [  60/1093] d_loss: 1.33201087, g_loss: 0.65112042\n",
      "Epoch: [ 9] [  80/1093] d_loss: 1.30018282, g_loss: 0.67127812\n",
      "Epoch: [ 9] [ 100/1093] d_loss: 1.27962995, g_loss: 0.64765501\n",
      "save down\n",
      "Epoch: [ 9] [ 120/1093] d_loss: 1.27742815, g_loss: 0.69547689\n",
      "Epoch: [ 9] [ 140/1093] d_loss: 1.24748707, g_loss: 0.64342761\n",
      "Epoch: [ 9] [ 160/1093] d_loss: 1.30192256, g_loss: 0.64198017\n",
      "Epoch: [ 9] [ 180/1093] d_loss: 1.25197721, g_loss: 0.68077725\n",
      "Epoch: [ 9] [ 200/1093] d_loss: 1.15062594, g_loss: 0.73673624\n",
      "save down\n",
      "Epoch: [ 9] [ 220/1093] d_loss: 1.37091756, g_loss: 0.63580614\n",
      "Epoch: [ 9] [ 240/1093] d_loss: 1.25613916, g_loss: 0.64353025\n",
      "Epoch: [ 9] [ 260/1093] d_loss: 1.32191265, g_loss: 0.64218163\n",
      "Epoch: [ 9] [ 280/1093] d_loss: 1.26288927, g_loss: 0.67804319\n",
      "Epoch: [ 9] [ 300/1093] d_loss: 1.24345231, g_loss: 0.69251418\n",
      "save down\n",
      "Epoch: [ 9] [ 320/1093] d_loss: 1.23616004, g_loss: 0.67106104\n",
      "Epoch: [ 9] [ 340/1093] d_loss: 1.34165430, g_loss: 0.60930753\n",
      "Epoch: [ 9] [ 360/1093] d_loss: 1.27700734, g_loss: 0.69625175\n",
      "Epoch: [ 9] [ 380/1093] d_loss: 1.25044847, g_loss: 0.62177175\n",
      "Epoch: [ 9] [ 400/1093] d_loss: 1.29761875, g_loss: 0.60889173\n",
      "save down\n",
      "Epoch: [ 9] [ 420/1093] d_loss: 1.31553292, g_loss: 0.58058929\n",
      "Epoch: [ 9] [ 440/1093] d_loss: 1.21140802, g_loss: 0.69028836\n",
      "Epoch: [ 9] [ 460/1093] d_loss: 1.30385590, g_loss: 0.60331857\n",
      "Epoch: [ 9] [ 480/1093] d_loss: 1.31137753, g_loss: 0.63924593\n",
      "Epoch: [ 9] [ 500/1093] d_loss: 1.33321106, g_loss: 0.65406334\n",
      "save down\n",
      "Epoch: [ 9] [ 520/1093] d_loss: 1.21447587, g_loss: 0.67839074\n",
      "Epoch: [ 9] [ 540/1093] d_loss: 1.23954546, g_loss: 0.67928696\n",
      "Epoch: [ 9] [ 560/1093] d_loss: 1.31840789, g_loss: 0.59420639\n",
      "Epoch: [ 9] [ 580/1093] d_loss: 1.25758934, g_loss: 0.63053250\n",
      "Epoch: [ 9] [ 600/1093] d_loss: 1.28228831, g_loss: 0.63250500\n",
      "save down\n",
      "Epoch: [ 9] [ 620/1093] d_loss: 1.28968155, g_loss: 0.65124226\n",
      "Epoch: [ 9] [ 640/1093] d_loss: 1.28802276, g_loss: 0.64956892\n",
      "Epoch: [ 9] [ 660/1093] d_loss: 1.23475361, g_loss: 0.68346691\n",
      "Epoch: [ 9] [ 680/1093] d_loss: 1.28006589, g_loss: 0.62114459\n",
      "Epoch: [ 9] [ 700/1093] d_loss: 1.23685074, g_loss: 0.61535621\n",
      "save down\n",
      "Epoch: [ 9] [ 720/1093] d_loss: 1.29571283, g_loss: 0.60627002\n",
      "Epoch: [ 9] [ 740/1093] d_loss: 1.23011112, g_loss: 0.68771887\n",
      "Epoch: [ 9] [ 760/1093] d_loss: 1.30627060, g_loss: 0.59585762\n",
      "Epoch: [ 9] [ 780/1093] d_loss: 1.21961844, g_loss: 0.67601234\n",
      "Epoch: [ 9] [ 800/1093] d_loss: 1.23615336, g_loss: 0.68597239\n",
      "save down\n",
      "Epoch: [ 9] [ 820/1093] d_loss: 1.27704811, g_loss: 0.63552898\n",
      "Epoch: [ 9] [ 840/1093] d_loss: 1.28963947, g_loss: 0.63751149\n",
      "Epoch: [ 9] [ 860/1093] d_loss: 1.27048755, g_loss: 0.65722799\n",
      "Epoch: [ 9] [ 880/1093] d_loss: 1.22676134, g_loss: 0.65839577\n",
      "Epoch: [ 9] [ 900/1093] d_loss: 1.28868210, g_loss: 0.63295376\n",
      "save down\n",
      "Epoch: [ 9] [ 920/1093] d_loss: 1.25518036, g_loss: 0.62487680\n",
      "Epoch: [ 9] [ 940/1093] d_loss: 1.36426747, g_loss: 0.61003768\n",
      "Epoch: [ 9] [ 960/1093] d_loss: 1.18611348, g_loss: 0.67830992\n",
      "Epoch: [ 9] [ 980/1093] d_loss: 1.31382322, g_loss: 0.68596900\n",
      "Epoch: [ 9] [1000/1093] d_loss: 1.31125331, g_loss: 0.60408151\n",
      "save down\n",
      "Epoch: [ 9] [1020/1093] d_loss: 1.31324017, g_loss: 0.61282516\n",
      "Epoch: [ 9] [1040/1093] d_loss: 1.30100763, g_loss: 0.62119937\n",
      "Epoch: [ 9] [1060/1093] d_loss: 1.28844953, g_loss: 0.65340197\n",
      "Epoch: [ 9] [1080/1093] d_loss: 1.30218637, g_loss: 0.63149410\n",
      "Epoch: [10] [   0/1093] d_loss: 1.29649198, g_loss: 0.62406641\n",
      "save down\n",
      "Epoch: [10] [  20/1093] d_loss: 1.22077179, g_loss: 0.72075450\n",
      "Epoch: [10] [  40/1093] d_loss: 1.35554349, g_loss: 0.60659087\n",
      "Epoch: [10] [  60/1093] d_loss: 1.23723185, g_loss: 0.70020348\n",
      "Epoch: [10] [  80/1093] d_loss: 1.35457349, g_loss: 0.59391028\n",
      "Epoch: [10] [ 100/1093] d_loss: 1.26635194, g_loss: 0.62859493\n",
      "save down\n",
      "Epoch: [10] [ 120/1093] d_loss: 1.32275701, g_loss: 0.62921983\n",
      "Epoch: [10] [ 140/1093] d_loss: 1.30136001, g_loss: 0.60931796\n",
      "Epoch: [10] [ 160/1093] d_loss: 1.28080070, g_loss: 0.68461651\n",
      "Epoch: [10] [ 180/1093] d_loss: 1.29988921, g_loss: 0.62998211\n",
      "Epoch: [10] [ 200/1093] d_loss: 1.17637300, g_loss: 0.70142078\n",
      "save down\n",
      "Epoch: [10] [ 220/1093] d_loss: 1.22699237, g_loss: 0.72225964\n",
      "Epoch: [10] [ 240/1093] d_loss: 1.24233425, g_loss: 0.61698902\n",
      "Epoch: [10] [ 260/1093] d_loss: 1.28158534, g_loss: 0.66704476\n",
      "Epoch: [10] [ 280/1093] d_loss: 1.27599859, g_loss: 0.71154660\n",
      "Epoch: [10] [ 300/1093] d_loss: 1.25096202, g_loss: 0.66346419\n",
      "save down\n",
      "Epoch: [10] [ 320/1093] d_loss: 1.22715425, g_loss: 0.65970951\n",
      "Epoch: [10] [ 340/1093] d_loss: 1.29429770, g_loss: 0.66985595\n",
      "Epoch: [10] [ 360/1093] d_loss: 1.31998086, g_loss: 0.62797368\n",
      "Epoch: [10] [ 380/1093] d_loss: 1.22427440, g_loss: 0.66125035\n",
      "Epoch: [10] [ 400/1093] d_loss: 1.21501577, g_loss: 0.71091902\n",
      "save down\n",
      "Epoch: [10] [ 420/1093] d_loss: 1.26207507, g_loss: 0.64893782\n",
      "Epoch: [10] [ 440/1093] d_loss: 1.26196098, g_loss: 0.63589132\n",
      "Epoch: [10] [ 460/1093] d_loss: 1.27844691, g_loss: 0.60081553\n",
      "Epoch: [10] [ 480/1093] d_loss: 1.28039885, g_loss: 0.62459505\n",
      "Epoch: [10] [ 500/1093] d_loss: 1.36778951, g_loss: 0.59600222\n",
      "save down\n",
      "Epoch: [10] [ 520/1093] d_loss: 1.20736241, g_loss: 0.67241132\n",
      "Epoch: [10] [ 540/1093] d_loss: 1.27352834, g_loss: 0.61131954\n",
      "Epoch: [10] [ 560/1093] d_loss: 1.26190925, g_loss: 0.63063776\n",
      "Epoch: [10] [ 580/1093] d_loss: 1.26427722, g_loss: 0.65353751\n",
      "Epoch: [10] [ 600/1093] d_loss: 1.19790471, g_loss: 0.65663683\n",
      "save down\n",
      "Epoch: [10] [ 620/1093] d_loss: 1.21448231, g_loss: 0.68819153\n",
      "Epoch: [10] [ 640/1093] d_loss: 1.25657403, g_loss: 0.64610279\n",
      "Epoch: [10] [ 660/1093] d_loss: 1.27590990, g_loss: 0.66510552\n",
      "Epoch: [10] [ 680/1093] d_loss: 1.27737045, g_loss: 0.64101541\n",
      "Epoch: [10] [ 700/1093] d_loss: 1.28371477, g_loss: 0.59060806\n",
      "save down\n",
      "Epoch: [10] [ 720/1093] d_loss: 1.28029799, g_loss: 0.66177148\n",
      "Epoch: [10] [ 740/1093] d_loss: 1.23936582, g_loss: 0.68989146\n",
      "Epoch: [10] [ 760/1093] d_loss: 1.25277090, g_loss: 0.63506067\n",
      "Epoch: [10] [ 780/1093] d_loss: 1.22603393, g_loss: 0.62870991\n",
      "Epoch: [10] [ 800/1093] d_loss: 1.24199343, g_loss: 0.61962372\n",
      "save down\n",
      "Epoch: [10] [ 820/1093] d_loss: 1.19726896, g_loss: 0.70628309\n",
      "Epoch: [10] [ 840/1093] d_loss: 1.29912543, g_loss: 0.58171737\n",
      "Epoch: [10] [ 860/1093] d_loss: 1.31653190, g_loss: 0.60949939\n",
      "Epoch: [10] [ 880/1093] d_loss: 1.26147532, g_loss: 0.63446546\n",
      "Epoch: [10] [ 900/1093] d_loss: 1.22411013, g_loss: 0.67266095\n",
      "save down\n",
      "Epoch: [10] [ 920/1093] d_loss: 1.26615596, g_loss: 0.63257265\n",
      "Epoch: [10] [ 940/1093] d_loss: 1.33898878, g_loss: 0.59470248\n",
      "Epoch: [10] [ 960/1093] d_loss: 1.18120980, g_loss: 0.68207788\n",
      "Epoch: [10] [ 980/1093] d_loss: 1.40279961, g_loss: 0.54633117\n",
      "Epoch: [10] [1000/1093] d_loss: 1.29499221, g_loss: 0.65752155\n",
      "save down\n",
      "Epoch: [10] [1020/1093] d_loss: 1.21867728, g_loss: 0.68001121\n",
      "Epoch: [10] [1040/1093] d_loss: 1.27381933, g_loss: 0.62745363\n",
      "Epoch: [10] [1060/1093] d_loss: 1.20833051, g_loss: 0.67991823\n",
      "Epoch: [10] [1080/1093] d_loss: 1.26503277, g_loss: 0.66654980\n",
      "Epoch: [11] [   0/1093] d_loss: 1.26764810, g_loss: 0.61458343\n",
      "save down\n",
      "Epoch: [11] [  20/1093] d_loss: 1.32785201, g_loss: 0.66722882\n",
      "Epoch: [11] [  40/1093] d_loss: 1.24684191, g_loss: 0.65681612\n",
      "Epoch: [11] [  60/1093] d_loss: 1.24378490, g_loss: 0.68504906\n",
      "Epoch: [11] [  80/1093] d_loss: 1.21133077, g_loss: 0.74159706\n",
      "Epoch: [11] [ 100/1093] d_loss: 1.27471960, g_loss: 0.64969790\n",
      "save down\n",
      "Epoch: [11] [ 120/1093] d_loss: 1.29270256, g_loss: 0.68025035\n",
      "Epoch: [11] [ 140/1093] d_loss: 1.22335446, g_loss: 0.65517503\n",
      "Epoch: [11] [ 160/1093] d_loss: 1.24201632, g_loss: 0.65554053\n",
      "Epoch: [11] [ 180/1093] d_loss: 1.23377490, g_loss: 0.67159414\n",
      "Epoch: [11] [ 200/1093] d_loss: 1.16109061, g_loss: 0.67682958\n",
      "save down\n",
      "Epoch: [11] [ 220/1093] d_loss: 1.24077559, g_loss: 0.72077596\n",
      "Epoch: [11] [ 240/1093] d_loss: 1.24762583, g_loss: 0.60098696\n",
      "Epoch: [11] [ 260/1093] d_loss: 1.26202393, g_loss: 0.64535755\n",
      "Epoch: [11] [ 280/1093] d_loss: 1.25233245, g_loss: 0.67358780\n",
      "Epoch: [11] [ 300/1093] d_loss: 1.26409793, g_loss: 0.66405195\n",
      "save down\n",
      "Epoch: [11] [ 320/1093] d_loss: 1.22200584, g_loss: 0.65408373\n",
      "Epoch: [11] [ 340/1093] d_loss: 1.19693875, g_loss: 0.69482422\n",
      "Epoch: [11] [ 360/1093] d_loss: 1.23890948, g_loss: 0.65323448\n",
      "Epoch: [11] [ 380/1093] d_loss: 1.19578743, g_loss: 0.63111103\n",
      "Epoch: [11] [ 400/1093] d_loss: 1.32085085, g_loss: 0.62640762\n",
      "save down\n",
      "Epoch: [11] [ 420/1093] d_loss: 1.21385980, g_loss: 0.64851081\n",
      "Epoch: [11] [ 440/1093] d_loss: 1.31656480, g_loss: 0.57467854\n",
      "Epoch: [11] [ 460/1093] d_loss: 1.29195726, g_loss: 0.66636300\n",
      "Epoch: [11] [ 480/1093] d_loss: 1.23282909, g_loss: 0.65139347\n",
      "Epoch: [11] [ 500/1093] d_loss: 1.28971291, g_loss: 0.63426501\n",
      "save down\n",
      "Epoch: [11] [ 520/1093] d_loss: 1.24850142, g_loss: 0.67111301\n",
      "Epoch: [11] [ 540/1093] d_loss: 1.24065781, g_loss: 0.66545022\n",
      "Epoch: [11] [ 560/1093] d_loss: 1.26451349, g_loss: 0.64327508\n",
      "Epoch: [11] [ 580/1093] d_loss: 1.23988390, g_loss: 0.64952612\n",
      "Epoch: [11] [ 600/1093] d_loss: 1.25864530, g_loss: 0.63470304\n",
      "save down\n",
      "Epoch: [11] [ 620/1093] d_loss: 1.23924649, g_loss: 0.66753584\n",
      "Epoch: [11] [ 640/1093] d_loss: 1.25058556, g_loss: 0.60779917\n",
      "Epoch: [11] [ 660/1093] d_loss: 1.26459336, g_loss: 0.68284267\n",
      "Epoch: [11] [ 680/1093] d_loss: 1.15890038, g_loss: 0.70180273\n",
      "Epoch: [11] [ 700/1093] d_loss: 1.22103477, g_loss: 0.65931040\n",
      "save down\n",
      "Epoch: [11] [ 720/1093] d_loss: 1.23203313, g_loss: 0.61081636\n",
      "Epoch: [11] [ 740/1093] d_loss: 1.22256947, g_loss: 0.67391282\n",
      "Epoch: [11] [ 760/1093] d_loss: 1.31534708, g_loss: 0.60133618\n",
      "Epoch: [11] [ 780/1093] d_loss: 1.19734323, g_loss: 0.69877565\n",
      "Epoch: [11] [ 800/1093] d_loss: 1.20648265, g_loss: 0.66889769\n",
      "save down\n",
      "Epoch: [11] [ 820/1093] d_loss: 1.29050219, g_loss: 0.59543985\n",
      "Epoch: [11] [ 840/1093] d_loss: 1.16898870, g_loss: 0.69742733\n",
      "Epoch: [11] [ 860/1093] d_loss: 1.30278134, g_loss: 0.63539195\n",
      "Epoch: [11] [ 880/1093] d_loss: 1.31520152, g_loss: 0.63865650\n",
      "Epoch: [11] [ 900/1093] d_loss: 1.27512395, g_loss: 0.60312802\n",
      "save down\n",
      "Epoch: [11] [ 920/1093] d_loss: 1.25064778, g_loss: 0.62802160\n",
      "Epoch: [11] [ 940/1093] d_loss: 1.24303532, g_loss: 0.66399556\n",
      "Epoch: [11] [ 960/1093] d_loss: 1.24797654, g_loss: 0.66521382\n",
      "Epoch: [11] [ 980/1093] d_loss: 1.30967212, g_loss: 0.62941259\n",
      "Epoch: [11] [1000/1093] d_loss: 1.21118546, g_loss: 0.68452442\n",
      "save down\n",
      "Epoch: [11] [1020/1093] d_loss: 1.29088235, g_loss: 0.60917675\n",
      "Epoch: [11] [1040/1093] d_loss: 1.23732209, g_loss: 0.63667321\n",
      "Epoch: [11] [1060/1093] d_loss: 1.18141711, g_loss: 0.69909430\n",
      "Epoch: [11] [1080/1093] d_loss: 1.26142561, g_loss: 0.62611020\n",
      "Epoch: [12] [   0/1093] d_loss: 1.24910569, g_loss: 0.65179425\n",
      "save down\n",
      "Epoch: [12] [  20/1093] d_loss: 1.32426023, g_loss: 0.63160920\n",
      "Epoch: [12] [  40/1093] d_loss: 1.23127675, g_loss: 0.66038775\n",
      "Epoch: [12] [  60/1093] d_loss: 1.25016379, g_loss: 0.65658092\n",
      "Epoch: [12] [  80/1093] d_loss: 1.29962277, g_loss: 0.65473062\n",
      "Epoch: [12] [ 100/1093] d_loss: 1.22105873, g_loss: 0.65728718\n",
      "save down\n",
      "Epoch: [12] [ 120/1093] d_loss: 1.22579670, g_loss: 0.67385972\n",
      "Epoch: [12] [ 140/1093] d_loss: 1.31790066, g_loss: 0.59200937\n",
      "Epoch: [12] [ 160/1093] d_loss: 1.24892581, g_loss: 0.65852314\n",
      "Epoch: [12] [ 180/1093] d_loss: 1.17679024, g_loss: 0.69703257\n",
      "Epoch: [12] [ 200/1093] d_loss: 1.18646908, g_loss: 0.70709008\n",
      "save down\n",
      "Epoch: [12] [ 220/1093] d_loss: 1.31360900, g_loss: 0.64170641\n",
      "Epoch: [12] [ 240/1093] d_loss: 1.22476625, g_loss: 0.65371215\n",
      "Epoch: [12] [ 260/1093] d_loss: 1.20554197, g_loss: 0.73413765\n",
      "Epoch: [12] [ 280/1093] d_loss: 1.21375036, g_loss: 0.65325785\n",
      "Epoch: [12] [ 300/1093] d_loss: 1.25478709, g_loss: 0.75071281\n",
      "save down\n",
      "Epoch: [12] [ 320/1093] d_loss: 1.19216013, g_loss: 0.66737407\n",
      "Epoch: [12] [ 340/1093] d_loss: 1.23252606, g_loss: 0.64009231\n",
      "Epoch: [12] [ 360/1093] d_loss: 1.29857743, g_loss: 0.66071856\n",
      "Epoch: [12] [ 380/1093] d_loss: 1.23631597, g_loss: 0.64594990\n",
      "Epoch: [12] [ 400/1093] d_loss: 1.27878761, g_loss: 0.61930728\n",
      "save down\n",
      "Epoch: [12] [ 420/1093] d_loss: 1.23808563, g_loss: 0.64843625\n",
      "Epoch: [12] [ 440/1093] d_loss: 1.17382407, g_loss: 0.71881080\n",
      "Epoch: [12] [ 460/1093] d_loss: 1.21278346, g_loss: 0.63190621\n",
      "Epoch: [12] [ 480/1093] d_loss: 1.28430581, g_loss: 0.65480775\n",
      "Epoch: [12] [ 500/1093] d_loss: 1.34081352, g_loss: 0.62369817\n",
      "save down\n",
      "Epoch: [12] [ 520/1093] d_loss: 1.17376232, g_loss: 0.70347989\n",
      "Epoch: [12] [ 540/1093] d_loss: 1.27440989, g_loss: 0.63505781\n",
      "Epoch: [12] [ 560/1093] d_loss: 1.22404075, g_loss: 0.66826695\n",
      "Epoch: [12] [ 580/1093] d_loss: 1.28693521, g_loss: 0.56377077\n",
      "Epoch: [12] [ 600/1093] d_loss: 1.35065961, g_loss: 0.56336272\n",
      "save down\n",
      "Epoch: [12] [ 620/1093] d_loss: 1.20135534, g_loss: 0.68402159\n",
      "Epoch: [12] [ 640/1093] d_loss: 1.28762412, g_loss: 0.59084892\n",
      "Epoch: [12] [ 660/1093] d_loss: 1.18181419, g_loss: 0.68795180\n",
      "Epoch: [12] [ 680/1093] d_loss: 1.16400909, g_loss: 0.73946357\n",
      "Epoch: [12] [ 700/1093] d_loss: 1.23377061, g_loss: 0.62918627\n",
      "save down\n",
      "Epoch: [12] [ 720/1093] d_loss: 1.26176238, g_loss: 0.67189282\n",
      "Epoch: [12] [ 740/1093] d_loss: 1.29670656, g_loss: 0.61895990\n",
      "Epoch: [12] [ 760/1093] d_loss: 1.26625252, g_loss: 0.63895249\n",
      "Epoch: [12] [ 780/1093] d_loss: 1.19572353, g_loss: 0.63146800\n",
      "Epoch: [12] [ 800/1093] d_loss: 1.16840768, g_loss: 0.70861089\n",
      "save down\n",
      "Epoch: [12] [ 820/1093] d_loss: 1.16114020, g_loss: 0.72728491\n",
      "Epoch: [12] [ 840/1093] d_loss: 1.17818236, g_loss: 0.70100081\n",
      "Epoch: [12] [ 860/1093] d_loss: 1.22730172, g_loss: 0.65067351\n",
      "Epoch: [12] [ 880/1093] d_loss: 1.17706239, g_loss: 0.65245336\n",
      "Epoch: [12] [ 900/1093] d_loss: 1.21260810, g_loss: 0.68491411\n",
      "save down\n",
      "Epoch: [12] [ 920/1093] d_loss: 1.25518620, g_loss: 0.59550673\n",
      "Epoch: [12] [ 940/1093] d_loss: 1.28011703, g_loss: 0.61402649\n",
      "Epoch: [12] [ 960/1093] d_loss: 1.17373419, g_loss: 0.64437366\n",
      "Epoch: [12] [ 980/1093] d_loss: 1.22504306, g_loss: 0.71379733\n",
      "Epoch: [12] [1000/1093] d_loss: 1.22565413, g_loss: 0.66670418\n",
      "save down\n",
      "Epoch: [12] [1020/1093] d_loss: 1.18310010, g_loss: 0.66817689\n",
      "Epoch: [12] [1040/1093] d_loss: 1.22839701, g_loss: 0.62302923\n",
      "Epoch: [12] [1060/1093] d_loss: 1.25962758, g_loss: 0.67940259\n",
      "Epoch: [12] [1080/1093] d_loss: 1.25584817, g_loss: 0.60980517\n",
      "Epoch: [13] [   0/1093] d_loss: 1.18599486, g_loss: 0.70828003\n",
      "save down\n",
      "Epoch: [13] [  20/1093] d_loss: 1.20169115, g_loss: 0.71167076\n",
      "Epoch: [13] [  40/1093] d_loss: 1.30946732, g_loss: 0.65319300\n",
      "Epoch: [13] [  60/1093] d_loss: 1.20148659, g_loss: 0.74172974\n",
      "Epoch: [13] [  80/1093] d_loss: 1.25184631, g_loss: 0.63467896\n",
      "Epoch: [13] [ 100/1093] d_loss: 1.19184399, g_loss: 0.64944619\n",
      "save down\n",
      "Epoch: [13] [ 120/1093] d_loss: 1.31134260, g_loss: 0.72210550\n",
      "Epoch: [13] [ 140/1093] d_loss: 1.21287727, g_loss: 0.67982680\n",
      "Epoch: [13] [ 160/1093] d_loss: 1.21498179, g_loss: 0.66098619\n",
      "Epoch: [13] [ 180/1093] d_loss: 1.30170727, g_loss: 0.61781311\n",
      "Epoch: [13] [ 200/1093] d_loss: 1.20311427, g_loss: 0.65575504\n",
      "save down\n",
      "Epoch: [13] [ 220/1093] d_loss: 1.19074249, g_loss: 0.72543770\n",
      "Epoch: [13] [ 240/1093] d_loss: 1.18935347, g_loss: 0.65984672\n",
      "Epoch: [13] [ 260/1093] d_loss: 1.26118135, g_loss: 0.62565732\n",
      "Epoch: [13] [ 280/1093] d_loss: 1.26485920, g_loss: 0.66067231\n",
      "Epoch: [13] [ 300/1093] d_loss: 1.22283006, g_loss: 0.71335346\n",
      "save down\n",
      "Epoch: [13] [ 320/1093] d_loss: 1.23466730, g_loss: 0.63332605\n",
      "Epoch: [13] [ 340/1093] d_loss: 1.31339741, g_loss: 0.59757555\n",
      "Epoch: [13] [ 360/1093] d_loss: 1.27655315, g_loss: 0.63575339\n",
      "Epoch: [13] [ 380/1093] d_loss: 1.20265162, g_loss: 0.61443448\n",
      "Epoch: [13] [ 400/1093] d_loss: 1.22208810, g_loss: 0.64266860\n",
      "save down\n",
      "Epoch: [13] [ 420/1093] d_loss: 1.21048892, g_loss: 0.67152297\n",
      "Epoch: [13] [ 440/1093] d_loss: 1.21447110, g_loss: 0.63864696\n",
      "Epoch: [13] [ 460/1093] d_loss: 1.21268129, g_loss: 0.67531812\n",
      "Epoch: [13] [ 480/1093] d_loss: 1.33572972, g_loss: 0.61209261\n",
      "Epoch: [13] [ 500/1093] d_loss: 1.27125192, g_loss: 0.68858808\n",
      "save down\n",
      "Epoch: [13] [ 520/1093] d_loss: 1.25268793, g_loss: 0.67390776\n",
      "Epoch: [13] [ 540/1093] d_loss: 1.24826384, g_loss: 0.58618242\n",
      "Epoch: [13] [ 560/1093] d_loss: 1.14254165, g_loss: 0.68395340\n",
      "Epoch: [13] [ 580/1093] d_loss: 1.27732790, g_loss: 0.60477138\n",
      "Epoch: [13] [ 600/1093] d_loss: 1.21985877, g_loss: 0.62937528\n",
      "save down\n",
      "Epoch: [13] [ 620/1093] d_loss: 1.21125174, g_loss: 0.69669068\n",
      "Epoch: [13] [ 640/1093] d_loss: 1.35581422, g_loss: 0.56696796\n",
      "Epoch: [13] [ 660/1093] d_loss: 1.20615005, g_loss: 0.65902704\n",
      "Epoch: [13] [ 680/1093] d_loss: 1.18847728, g_loss: 0.69230878\n",
      "Epoch: [13] [ 700/1093] d_loss: 1.10896754, g_loss: 0.72135884\n",
      "save down\n",
      "Epoch: [13] [ 720/1093] d_loss: 1.25033832, g_loss: 0.63653696\n",
      "Epoch: [13] [ 740/1093] d_loss: 1.32438862, g_loss: 0.59536648\n",
      "Epoch: [13] [ 760/1093] d_loss: 1.23067713, g_loss: 0.66946876\n",
      "Epoch: [13] [ 780/1093] d_loss: 1.17543113, g_loss: 0.70301473\n",
      "Epoch: [13] [ 800/1093] d_loss: 1.20553446, g_loss: 0.66771770\n",
      "save down\n",
      "Epoch: [13] [ 820/1093] d_loss: 1.28241408, g_loss: 0.64686090\n",
      "Epoch: [13] [ 840/1093] d_loss: 1.15373945, g_loss: 0.71098197\n",
      "Epoch: [13] [ 860/1093] d_loss: 1.25053763, g_loss: 0.60990804\n",
      "Epoch: [13] [ 880/1093] d_loss: 1.11647451, g_loss: 0.74669480\n",
      "Epoch: [13] [ 900/1093] d_loss: 1.23724401, g_loss: 0.64050698\n",
      "save down\n",
      "Epoch: [13] [ 920/1093] d_loss: 1.16956007, g_loss: 0.66860139\n",
      "Epoch: [13] [ 940/1093] d_loss: 1.31844473, g_loss: 0.62445301\n",
      "Epoch: [13] [ 960/1093] d_loss: 1.09788370, g_loss: 0.71267730\n",
      "Epoch: [13] [ 980/1093] d_loss: 1.21936917, g_loss: 0.66301924\n",
      "Epoch: [13] [1000/1093] d_loss: 1.23576736, g_loss: 0.70635355\n",
      "save down\n",
      "Epoch: [13] [1020/1093] d_loss: 1.23067403, g_loss: 0.67196929\n",
      "Epoch: [13] [1040/1093] d_loss: 1.19141066, g_loss: 0.63975966\n",
      "Epoch: [13] [1060/1093] d_loss: 1.27459812, g_loss: 0.63638884\n",
      "Epoch: [13] [1080/1093] d_loss: 1.24346054, g_loss: 0.65090930\n",
      "Epoch: [14] [   0/1093] d_loss: 1.25927353, g_loss: 0.62860030\n",
      "save down\n",
      "Epoch: [14] [  20/1093] d_loss: 1.19604611, g_loss: 0.65924978\n",
      "Epoch: [14] [  40/1093] d_loss: 1.29257393, g_loss: 0.60513580\n",
      "Epoch: [14] [  60/1093] d_loss: 1.20835793, g_loss: 0.72619629\n",
      "Epoch: [14] [  80/1093] d_loss: 1.33902013, g_loss: 0.60836279\n",
      "Epoch: [14] [ 100/1093] d_loss: 1.18087566, g_loss: 0.66827297\n",
      "save down\n",
      "Epoch: [14] [ 120/1093] d_loss: 1.16296780, g_loss: 0.73416525\n",
      "Epoch: [14] [ 140/1093] d_loss: 1.29809749, g_loss: 0.58157492\n",
      "Epoch: [14] [ 160/1093] d_loss: 1.22836721, g_loss: 0.68093503\n",
      "Epoch: [14] [ 180/1093] d_loss: 1.18093073, g_loss: 0.68138081\n",
      "Epoch: [14] [ 200/1093] d_loss: 1.12087953, g_loss: 0.74232543\n",
      "save down\n",
      "Epoch: [14] [ 220/1093] d_loss: 1.27263379, g_loss: 0.69672483\n",
      "Epoch: [14] [ 240/1093] d_loss: 1.19596815, g_loss: 0.65152079\n",
      "Epoch: [14] [ 260/1093] d_loss: 1.15924752, g_loss: 0.74052364\n",
      "Epoch: [14] [ 280/1093] d_loss: 1.27067935, g_loss: 0.66071475\n",
      "Epoch: [14] [ 300/1093] d_loss: 1.23080063, g_loss: 0.70116866\n",
      "save down\n",
      "Epoch: [14] [ 320/1093] d_loss: 1.21667862, g_loss: 0.64203572\n",
      "Epoch: [14] [ 340/1093] d_loss: 1.31147814, g_loss: 0.59232867\n",
      "Epoch: [14] [ 360/1093] d_loss: 1.24689829, g_loss: 0.64435947\n",
      "Epoch: [14] [ 380/1093] d_loss: 1.23390603, g_loss: 0.62717175\n",
      "Epoch: [14] [ 400/1093] d_loss: 1.22517562, g_loss: 0.65074724\n",
      "save down\n",
      "Epoch: [14] [ 420/1093] d_loss: 1.16082656, g_loss: 0.72420597\n",
      "Epoch: [14] [ 440/1093] d_loss: 1.19681585, g_loss: 0.61630148\n",
      "Epoch: [14] [ 460/1093] d_loss: 1.16964376, g_loss: 0.66263205\n",
      "Epoch: [14] [ 480/1093] d_loss: 1.19875371, g_loss: 0.72915065\n",
      "Epoch: [14] [ 500/1093] d_loss: 1.24774516, g_loss: 0.63415331\n",
      "save down\n",
      "Epoch: [14] [ 520/1093] d_loss: 1.17204165, g_loss: 0.71412939\n",
      "Epoch: [14] [ 540/1093] d_loss: 1.23559976, g_loss: 0.62505507\n",
      "Epoch: [14] [ 560/1093] d_loss: 1.24434745, g_loss: 0.65774500\n",
      "Epoch: [14] [ 580/1093] d_loss: 1.18364501, g_loss: 0.64837080\n",
      "Epoch: [14] [ 600/1093] d_loss: 1.30066133, g_loss: 0.57675982\n",
      "save down\n",
      "Epoch: [14] [ 620/1093] d_loss: 1.14732695, g_loss: 0.68658274\n",
      "Epoch: [14] [ 640/1093] d_loss: 1.26204705, g_loss: 0.61851394\n",
      "Epoch: [14] [ 660/1093] d_loss: 1.20178556, g_loss: 0.67698860\n",
      "Epoch: [14] [ 680/1093] d_loss: 1.19535899, g_loss: 0.70638371\n",
      "Epoch: [14] [ 700/1093] d_loss: 1.06871498, g_loss: 0.79133534\n",
      "save down\n",
      "Epoch: [14] [ 720/1093] d_loss: 1.18851829, g_loss: 0.70870590\n",
      "Epoch: [14] [ 740/1093] d_loss: 1.19873261, g_loss: 0.68786681\n",
      "Epoch: [14] [ 760/1093] d_loss: 1.25239372, g_loss: 0.62249088\n",
      "Epoch: [14] [ 780/1093] d_loss: 1.17114353, g_loss: 0.72080022\n",
      "Epoch: [14] [ 800/1093] d_loss: 1.20046663, g_loss: 0.65652335\n",
      "save down\n",
      "Epoch: [14] [ 820/1093] d_loss: 1.20067525, g_loss: 0.66382509\n",
      "Epoch: [14] [ 840/1093] d_loss: 1.17274594, g_loss: 0.66353106\n",
      "Epoch: [14] [ 860/1093] d_loss: 1.19370878, g_loss: 0.61727524\n",
      "Epoch: [14] [ 880/1093] d_loss: 1.23966336, g_loss: 0.62889051\n",
      "Epoch: [14] [ 900/1093] d_loss: 1.24300349, g_loss: 0.64093524\n",
      "save down\n",
      "Epoch: [14] [ 920/1093] d_loss: 1.24137306, g_loss: 0.62022018\n",
      "Epoch: [14] [ 940/1093] d_loss: 1.26389146, g_loss: 0.67345345\n",
      "Epoch: [14] [ 960/1093] d_loss: 1.11944020, g_loss: 0.69014132\n",
      "Epoch: [14] [ 980/1093] d_loss: 1.20753515, g_loss: 0.68190795\n",
      "Epoch: [14] [1000/1093] d_loss: 1.21314847, g_loss: 0.72272986\n",
      "save down\n",
      "Epoch: [14] [1020/1093] d_loss: 1.18833780, g_loss: 0.66884154\n",
      "Epoch: [14] [1040/1093] d_loss: 1.19540787, g_loss: 0.67829257\n",
      "Epoch: [14] [1060/1093] d_loss: 1.16545272, g_loss: 0.65399092\n",
      "Epoch: [14] [1080/1093] d_loss: 1.24894118, g_loss: 0.64295506\n",
      "Epoch: [15] [   0/1093] d_loss: 1.29304338, g_loss: 0.63280201\n",
      "save down\n",
      "Epoch: [15] [  20/1093] d_loss: 1.18233752, g_loss: 0.72769243\n",
      "Epoch: [15] [  40/1093] d_loss: 1.18757248, g_loss: 0.68066084\n",
      "Epoch: [15] [  60/1093] d_loss: 1.20881605, g_loss: 0.71697176\n",
      "Epoch: [15] [  80/1093] d_loss: 1.17815983, g_loss: 0.73664719\n",
      "Epoch: [15] [ 100/1093] d_loss: 1.22246051, g_loss: 0.66594142\n",
      "save down\n",
      "Epoch: [15] [ 120/1093] d_loss: 1.20500851, g_loss: 0.68458045\n",
      "Epoch: [15] [ 140/1093] d_loss: 1.17911458, g_loss: 0.64734793\n",
      "Epoch: [15] [ 160/1093] d_loss: 1.17270935, g_loss: 0.69539988\n",
      "Epoch: [15] [ 180/1093] d_loss: 1.19553137, g_loss: 0.64876401\n",
      "Epoch: [15] [ 200/1093] d_loss: 1.12962651, g_loss: 0.69894081\n",
      "save down\n",
      "Epoch: [15] [ 220/1093] d_loss: 1.14084792, g_loss: 0.72412813\n",
      "Epoch: [15] [ 240/1093] d_loss: 1.17946982, g_loss: 0.66008312\n",
      "Epoch: [15] [ 260/1093] d_loss: 1.07250679, g_loss: 0.79536200\n",
      "Epoch: [15] [ 280/1093] d_loss: 1.20626450, g_loss: 0.66077900\n",
      "Epoch: [15] [ 300/1093] d_loss: 1.15334785, g_loss: 0.73345917\n",
      "save down\n",
      "Epoch: [15] [ 320/1093] d_loss: 1.21246433, g_loss: 0.59491861\n",
      "Epoch: [15] [ 340/1093] d_loss: 1.15730500, g_loss: 0.67864347\n",
      "Epoch: [15] [ 360/1093] d_loss: 1.26737535, g_loss: 0.62220234\n",
      "Epoch: [15] [ 380/1093] d_loss: 1.17411077, g_loss: 0.63223755\n",
      "Epoch: [15] [ 400/1093] d_loss: 1.20482779, g_loss: 0.65099204\n",
      "save down\n",
      "Epoch: [15] [ 420/1093] d_loss: 1.21861899, g_loss: 0.81086457\n",
      "Epoch: [15] [ 440/1093] d_loss: 1.18376064, g_loss: 0.66204953\n",
      "Epoch: [15] [ 460/1093] d_loss: 1.22442257, g_loss: 0.64057505\n",
      "Epoch: [15] [ 480/1093] d_loss: 1.20864844, g_loss: 0.66152012\n",
      "Epoch: [15] [ 500/1093] d_loss: 1.23515809, g_loss: 0.68173110\n",
      "save down\n",
      "Epoch: [15] [ 520/1093] d_loss: 1.07701588, g_loss: 0.77710569\n",
      "Epoch: [15] [ 540/1093] d_loss: 1.13710546, g_loss: 0.66523415\n",
      "Epoch: [15] [ 560/1093] d_loss: 1.18297398, g_loss: 0.72599334\n",
      "Epoch: [15] [ 580/1093] d_loss: 1.17334151, g_loss: 0.66383052\n",
      "Epoch: [15] [ 600/1093] d_loss: 1.13646770, g_loss: 0.66406447\n",
      "save down\n",
      "Epoch: [15] [ 620/1093] d_loss: 1.25423408, g_loss: 0.66420346\n",
      "Epoch: [15] [ 640/1093] d_loss: 1.24508536, g_loss: 0.64518213\n",
      "Epoch: [15] [ 660/1093] d_loss: 1.13578129, g_loss: 0.69862282\n",
      "Epoch: [15] [ 680/1093] d_loss: 1.17800069, g_loss: 0.68552691\n",
      "Epoch: [15] [ 700/1093] d_loss: 1.15282321, g_loss: 0.69514930\n",
      "save down\n",
      "Epoch: [15] [ 720/1093] d_loss: 1.11937618, g_loss: 0.70441449\n",
      "Epoch: [15] [ 740/1093] d_loss: 1.29848146, g_loss: 0.61950046\n",
      "Epoch: [15] [ 760/1093] d_loss: 1.22860837, g_loss: 0.64326930\n",
      "Epoch: [15] [ 780/1093] d_loss: 1.17326474, g_loss: 0.64320982\n",
      "Epoch: [15] [ 800/1093] d_loss: 1.19206274, g_loss: 0.68248230\n",
      "save down\n",
      "Epoch: [15] [ 820/1093] d_loss: 1.15085816, g_loss: 0.70690662\n",
      "Epoch: [15] [ 840/1093] d_loss: 1.19760847, g_loss: 0.68943202\n",
      "Epoch: [15] [ 860/1093] d_loss: 1.25214195, g_loss: 0.59860450\n",
      "Epoch: [15] [ 880/1093] d_loss: 1.17719138, g_loss: 0.63180220\n",
      "Epoch: [15] [ 900/1093] d_loss: 1.20948339, g_loss: 0.62520647\n",
      "save down\n",
      "Epoch: [15] [ 920/1093] d_loss: 1.16203630, g_loss: 0.67839646\n",
      "Epoch: [15] [ 940/1093] d_loss: 1.21693027, g_loss: 0.65259242\n",
      "Epoch: [15] [ 960/1093] d_loss: 1.06047881, g_loss: 0.72602314\n",
      "Epoch: [15] [ 980/1093] d_loss: 1.26245248, g_loss: 0.69176090\n",
      "Epoch: [15] [1000/1093] d_loss: 1.12200093, g_loss: 0.73521638\n",
      "save down\n",
      "Epoch: [15] [1020/1093] d_loss: 1.13424444, g_loss: 0.68443280\n",
      "Epoch: [15] [1040/1093] d_loss: 1.17876065, g_loss: 0.62769628\n",
      "Epoch: [15] [1060/1093] d_loss: 1.29486609, g_loss: 0.60001493\n",
      "Epoch: [15] [1080/1093] d_loss: 1.17555714, g_loss: 0.72079551\n",
      "Epoch: [16] [   0/1093] d_loss: 1.23419642, g_loss: 0.61102033\n",
      "save down\n",
      "Epoch: [16] [  20/1093] d_loss: 1.24070120, g_loss: 0.62286842\n",
      "Epoch: [16] [  40/1093] d_loss: 1.28126979, g_loss: 0.62576979\n",
      "Epoch: [16] [  60/1093] d_loss: 1.13283038, g_loss: 0.71534526\n",
      "Epoch: [16] [  80/1093] d_loss: 1.18561172, g_loss: 0.70106798\n",
      "Epoch: [16] [ 100/1093] d_loss: 1.18795562, g_loss: 0.65358204\n",
      "save down\n",
      "Epoch: [16] [ 120/1093] d_loss: 1.22127438, g_loss: 0.72950798\n",
      "Epoch: [16] [ 140/1093] d_loss: 1.25085497, g_loss: 0.60580337\n",
      "Epoch: [16] [ 160/1093] d_loss: 1.22946191, g_loss: 0.64488256\n",
      "Epoch: [16] [ 180/1093] d_loss: 1.15157294, g_loss: 0.64698368\n",
      "Epoch: [16] [ 200/1093] d_loss: 1.10727072, g_loss: 0.71075439\n",
      "save down\n",
      "Epoch: [16] [ 220/1093] d_loss: 1.21502233, g_loss: 0.66889870\n",
      "Epoch: [16] [ 240/1093] d_loss: 1.07528102, g_loss: 0.76158988\n",
      "Epoch: [16] [ 260/1093] d_loss: 1.16654670, g_loss: 0.78517056\n",
      "Epoch: [16] [ 280/1093] d_loss: 1.15291238, g_loss: 0.70166874\n",
      "Epoch: [16] [ 300/1093] d_loss: 1.15158963, g_loss: 0.72723830\n",
      "save down\n",
      "Epoch: [16] [ 320/1093] d_loss: 1.19852042, g_loss: 0.65402138\n",
      "Epoch: [16] [ 340/1093] d_loss: 1.08553708, g_loss: 0.73047882\n",
      "Epoch: [16] [ 360/1093] d_loss: 1.22698581, g_loss: 0.67867637\n",
      "Epoch: [16] [ 380/1093] d_loss: 1.14109051, g_loss: 0.65954995\n",
      "Epoch: [16] [ 400/1093] d_loss: 1.17319059, g_loss: 0.67490035\n",
      "save down\n",
      "Epoch: [16] [ 420/1093] d_loss: 1.14615536, g_loss: 0.70614147\n",
      "Epoch: [16] [ 440/1093] d_loss: 1.13284147, g_loss: 0.67516935\n",
      "Epoch: [16] [ 460/1093] d_loss: 1.17948723, g_loss: 0.66481471\n",
      "Epoch: [16] [ 480/1093] d_loss: 1.24584830, g_loss: 0.65473890\n",
      "Epoch: [16] [ 500/1093] d_loss: 1.23156846, g_loss: 0.62598693\n",
      "save down\n",
      "Epoch: [16] [ 520/1093] d_loss: 1.14208019, g_loss: 0.72069001\n",
      "Epoch: [16] [ 540/1093] d_loss: 1.23624825, g_loss: 0.61977392\n",
      "Epoch: [16] [ 560/1093] d_loss: 1.17042601, g_loss: 0.71504807\n",
      "Epoch: [16] [ 580/1093] d_loss: 1.15000010, g_loss: 0.70410955\n",
      "Epoch: [16] [ 600/1093] d_loss: 1.19563150, g_loss: 0.61530304\n",
      "save down\n",
      "Epoch: [16] [ 620/1093] d_loss: 1.16196465, g_loss: 0.72229016\n",
      "Epoch: [16] [ 640/1093] d_loss: 1.19854403, g_loss: 0.68698210\n",
      "Epoch: [16] [ 660/1093] d_loss: 1.17669713, g_loss: 0.65873969\n",
      "Epoch: [16] [ 680/1093] d_loss: 1.15540433, g_loss: 0.68866891\n",
      "Epoch: [16] [ 700/1093] d_loss: 1.14333487, g_loss: 0.67703646\n",
      "save down\n",
      "Epoch: [16] [ 720/1093] d_loss: 1.14804196, g_loss: 0.63287234\n",
      "Epoch: [16] [ 740/1093] d_loss: 1.18526793, g_loss: 0.70077276\n",
      "Epoch: [16] [ 760/1093] d_loss: 1.14343214, g_loss: 0.65682405\n",
      "Epoch: [16] [ 780/1093] d_loss: 1.20921230, g_loss: 0.62952971\n",
      "Epoch: [16] [ 800/1093] d_loss: 1.20111203, g_loss: 0.62831926\n",
      "save down\n",
      "Epoch: [16] [ 820/1093] d_loss: 1.24017549, g_loss: 0.67312038\n",
      "Epoch: [16] [ 840/1093] d_loss: 1.10194159, g_loss: 0.73227680\n",
      "Epoch: [16] [ 860/1093] d_loss: 1.17422318, g_loss: 0.68094647\n",
      "Epoch: [16] [ 880/1093] d_loss: 1.09041667, g_loss: 0.78878409\n",
      "Epoch: [16] [ 900/1093] d_loss: 1.22275984, g_loss: 0.66920710\n",
      "save down\n",
      "Epoch: [16] [ 920/1093] d_loss: 1.24454188, g_loss: 0.57095200\n",
      "Epoch: [16] [ 940/1093] d_loss: 1.23182321, g_loss: 0.64581645\n",
      "Epoch: [16] [ 960/1093] d_loss: 1.16140807, g_loss: 0.63750827\n",
      "Epoch: [16] [ 980/1093] d_loss: 1.14901924, g_loss: 0.71431029\n",
      "Epoch: [16] [1000/1093] d_loss: 1.12392926, g_loss: 0.76083362\n",
      "save down\n",
      "Epoch: [16] [1020/1093] d_loss: 1.14300358, g_loss: 0.71606719\n",
      "Epoch: [16] [1040/1093] d_loss: 1.20575392, g_loss: 0.66079581\n",
      "Epoch: [16] [1060/1093] d_loss: 1.16334414, g_loss: 0.66583753\n",
      "Epoch: [16] [1080/1093] d_loss: 1.11852288, g_loss: 0.70491308\n",
      "Epoch: [17] [   0/1093] d_loss: 1.14109039, g_loss: 0.69154286\n",
      "save down\n",
      "Epoch: [17] [  20/1093] d_loss: 1.22512364, g_loss: 0.67716956\n",
      "Epoch: [17] [  40/1093] d_loss: 1.20068145, g_loss: 0.71134347\n",
      "Epoch: [17] [  60/1093] d_loss: 1.18813300, g_loss: 0.67923093\n",
      "Epoch: [17] [  80/1093] d_loss: 1.19368422, g_loss: 0.70472312\n",
      "Epoch: [17] [ 100/1093] d_loss: 1.15200686, g_loss: 0.64735651\n",
      "save down\n",
      "Epoch: [17] [ 120/1093] d_loss: 1.19820499, g_loss: 0.65879285\n",
      "Epoch: [17] [ 140/1093] d_loss: 1.16898322, g_loss: 0.65742922\n",
      "Epoch: [17] [ 160/1093] d_loss: 1.23650980, g_loss: 0.63062280\n",
      "Epoch: [17] [ 180/1093] d_loss: 1.22703981, g_loss: 0.63636303\n",
      "Epoch: [17] [ 200/1093] d_loss: 1.17582750, g_loss: 0.73324001\n",
      "save down\n",
      "Epoch: [17] [ 220/1093] d_loss: 1.16650248, g_loss: 0.68429834\n",
      "Epoch: [17] [ 240/1093] d_loss: 1.21455550, g_loss: 0.63476324\n",
      "Epoch: [17] [ 260/1093] d_loss: 1.09440470, g_loss: 0.77699411\n",
      "Epoch: [17] [ 280/1093] d_loss: 1.16895771, g_loss: 0.70573831\n",
      "Epoch: [17] [ 300/1093] d_loss: 1.13745165, g_loss: 0.78491056\n",
      "save down\n",
      "Epoch: [17] [ 320/1093] d_loss: 1.14149785, g_loss: 0.68450809\n",
      "Epoch: [17] [ 340/1093] d_loss: 1.18656325, g_loss: 0.68918890\n",
      "Epoch: [17] [ 360/1093] d_loss: 1.23328280, g_loss: 0.71149117\n",
      "Epoch: [17] [ 380/1093] d_loss: 1.13589406, g_loss: 0.64451516\n",
      "Epoch: [17] [ 400/1093] d_loss: 1.15885234, g_loss: 0.65184569\n",
      "save down\n",
      "Epoch: [17] [ 420/1093] d_loss: 1.15625918, g_loss: 0.65271175\n",
      "Epoch: [17] [ 440/1093] d_loss: 1.09595108, g_loss: 0.70822579\n",
      "Epoch: [17] [ 460/1093] d_loss: 1.06986558, g_loss: 0.75006759\n",
      "Epoch: [17] [ 480/1093] d_loss: 1.08482826, g_loss: 0.72277606\n",
      "Epoch: [17] [ 500/1093] d_loss: 1.21405840, g_loss: 0.71841741\n",
      "save down\n",
      "Epoch: [17] [ 520/1093] d_loss: 1.12729692, g_loss: 0.69062459\n",
      "Epoch: [17] [ 540/1093] d_loss: 1.17384672, g_loss: 0.63269538\n",
      "Epoch: [17] [ 560/1093] d_loss: 1.10628128, g_loss: 0.70537877\n",
      "Epoch: [17] [ 580/1093] d_loss: 1.08857608, g_loss: 0.71614748\n",
      "Epoch: [17] [ 600/1093] d_loss: 1.09664202, g_loss: 0.74189728\n",
      "save down\n",
      "Epoch: [17] [ 620/1093] d_loss: 1.13192821, g_loss: 0.71365017\n",
      "Epoch: [17] [ 640/1093] d_loss: 1.17330360, g_loss: 0.65245032\n",
      "Epoch: [17] [ 660/1093] d_loss: 1.13777208, g_loss: 0.68608606\n",
      "Epoch: [17] [ 680/1093] d_loss: 1.14281297, g_loss: 0.70851684\n",
      "Epoch: [17] [ 700/1093] d_loss: 1.18024111, g_loss: 0.65129936\n",
      "save down\n",
      "Epoch: [17] [ 720/1093] d_loss: 1.15645885, g_loss: 0.69526523\n",
      "Epoch: [17] [ 740/1093] d_loss: 1.24872005, g_loss: 0.59947294\n",
      "Epoch: [17] [ 760/1093] d_loss: 1.21187496, g_loss: 0.68409348\n",
      "Epoch: [17] [ 780/1093] d_loss: 1.16909516, g_loss: 0.67147672\n",
      "Epoch: [17] [ 800/1093] d_loss: 1.13587928, g_loss: 0.67511326\n",
      "save down\n",
      "Epoch: [17] [ 820/1093] d_loss: 1.09408927, g_loss: 0.80708134\n",
      "Epoch: [17] [ 840/1093] d_loss: 1.02393842, g_loss: 0.84066844\n",
      "Epoch: [17] [ 860/1093] d_loss: 1.19713092, g_loss: 0.67852902\n",
      "Epoch: [17] [ 880/1093] d_loss: 1.10766661, g_loss: 0.72043347\n",
      "Epoch: [17] [ 900/1093] d_loss: 1.15285695, g_loss: 0.67832732\n",
      "save down\n",
      "Epoch: [17] [ 920/1093] d_loss: 1.20970535, g_loss: 0.60485554\n",
      "Epoch: [17] [ 940/1093] d_loss: 1.17141950, g_loss: 0.65552580\n",
      "Epoch: [17] [ 960/1093] d_loss: 1.10476160, g_loss: 0.68659860\n",
      "Epoch: [17] [ 980/1093] d_loss: 1.17292094, g_loss: 0.67131025\n",
      "Epoch: [17] [1000/1093] d_loss: 1.16431880, g_loss: 0.76857221\n",
      "save down\n",
      "Epoch: [17] [1020/1093] d_loss: 1.06978798, g_loss: 0.69897580\n",
      "Epoch: [17] [1040/1093] d_loss: 1.08439326, g_loss: 0.72223377\n",
      "Epoch: [17] [1060/1093] d_loss: 1.16640413, g_loss: 0.61988133\n",
      "Epoch: [17] [1080/1093] d_loss: 1.17767596, g_loss: 0.66633779\n",
      "Epoch: [18] [   0/1093] d_loss: 1.17677069, g_loss: 0.64554882\n",
      "save down\n",
      "Epoch: [18] [  20/1093] d_loss: 1.08549762, g_loss: 0.75155306\n",
      "Epoch: [18] [  40/1093] d_loss: 1.24437273, g_loss: 0.64436895\n",
      "Epoch: [18] [  60/1093] d_loss: 1.14615798, g_loss: 0.70307684\n",
      "Epoch: [18] [  80/1093] d_loss: 1.18651116, g_loss: 0.65416652\n",
      "Epoch: [18] [ 100/1093] d_loss: 1.14299834, g_loss: 0.66918367\n",
      "save down\n",
      "Epoch: [18] [ 120/1093] d_loss: 1.19794559, g_loss: 0.82432652\n",
      "Epoch: [18] [ 140/1093] d_loss: 1.20819199, g_loss: 0.64024132\n",
      "Epoch: [18] [ 160/1093] d_loss: 1.10837162, g_loss: 0.78782630\n",
      "Epoch: [18] [ 180/1093] d_loss: 1.15287983, g_loss: 0.64669102\n",
      "Epoch: [18] [ 200/1093] d_loss: 1.10443115, g_loss: 0.73361838\n",
      "save down\n",
      "Epoch: [18] [ 220/1093] d_loss: 1.18178141, g_loss: 0.72184861\n",
      "Epoch: [18] [ 240/1093] d_loss: 1.09649026, g_loss: 0.69300961\n",
      "Epoch: [18] [ 260/1093] d_loss: 1.12176383, g_loss: 0.76729429\n",
      "Epoch: [18] [ 280/1093] d_loss: 1.09095681, g_loss: 0.76111579\n",
      "Epoch: [18] [ 300/1093] d_loss: 1.16624069, g_loss: 0.70862591\n",
      "save down\n",
      "Epoch: [18] [ 320/1093] d_loss: 1.24892759, g_loss: 0.66439253\n",
      "Epoch: [18] [ 340/1093] d_loss: 1.13301969, g_loss: 0.69374698\n",
      "Epoch: [18] [ 360/1093] d_loss: 1.14855957, g_loss: 0.70780313\n",
      "Epoch: [18] [ 380/1093] d_loss: 1.11881149, g_loss: 0.64219993\n",
      "Epoch: [18] [ 400/1093] d_loss: 1.19376040, g_loss: 0.66237384\n",
      "save down\n",
      "Epoch: [18] [ 420/1093] d_loss: 1.13529932, g_loss: 0.67327237\n",
      "Epoch: [18] [ 440/1093] d_loss: 1.13012576, g_loss: 0.65336448\n",
      "Epoch: [18] [ 460/1093] d_loss: 1.12516141, g_loss: 0.75750577\n",
      "Epoch: [18] [ 480/1093] d_loss: 1.12149000, g_loss: 0.73412466\n",
      "Epoch: [18] [ 500/1093] d_loss: 1.23367834, g_loss: 0.63184500\n",
      "save down\n",
      "Epoch: [18] [ 520/1093] d_loss: 1.24538851, g_loss: 0.61453915\n",
      "Epoch: [18] [ 540/1093] d_loss: 1.16788948, g_loss: 0.66087872\n",
      "Epoch: [18] [ 560/1093] d_loss: 1.14305222, g_loss: 0.65822256\n",
      "Epoch: [18] [ 580/1093] d_loss: 1.20031404, g_loss: 0.62118089\n",
      "Epoch: [18] [ 600/1093] d_loss: 1.13704634, g_loss: 0.66735303\n",
      "save down\n",
      "Epoch: [18] [ 620/1093] d_loss: 1.08667183, g_loss: 0.76962793\n",
      "Epoch: [18] [ 640/1093] d_loss: 1.17546237, g_loss: 0.67238629\n",
      "Epoch: [18] [ 660/1093] d_loss: 1.15579545, g_loss: 0.62468994\n",
      "Epoch: [18] [ 680/1093] d_loss: 1.15056229, g_loss: 0.78417671\n",
      "Epoch: [18] [ 700/1093] d_loss: 1.05840433, g_loss: 0.77715969\n",
      "save down\n",
      "Epoch: [18] [ 720/1093] d_loss: 1.18095446, g_loss: 0.60973167\n",
      "Epoch: [18] [ 740/1093] d_loss: 1.12022603, g_loss: 0.72232628\n",
      "Epoch: [18] [ 760/1093] d_loss: 1.05322492, g_loss: 0.72016448\n",
      "Epoch: [18] [ 780/1093] d_loss: 1.19799972, g_loss: 0.65397823\n",
      "Epoch: [18] [ 800/1093] d_loss: 1.13131797, g_loss: 0.66254914\n",
      "save down\n",
      "Epoch: [18] [ 820/1093] d_loss: 1.10389960, g_loss: 0.72979021\n",
      "Epoch: [18] [ 840/1093] d_loss: 1.14381957, g_loss: 0.68755144\n",
      "Epoch: [18] [ 860/1093] d_loss: 1.11736298, g_loss: 0.70655310\n",
      "Epoch: [18] [ 880/1093] d_loss: 1.16924357, g_loss: 0.65040642\n",
      "Epoch: [18] [ 900/1093] d_loss: 1.10873520, g_loss: 0.68766105\n",
      "save down\n",
      "Epoch: [18] [ 920/1093] d_loss: 1.19144940, g_loss: 0.62878948\n",
      "Epoch: [18] [ 940/1093] d_loss: 1.22904801, g_loss: 0.59293306\n",
      "Epoch: [18] [ 960/1093] d_loss: 1.19497693, g_loss: 0.61782289\n",
      "Epoch: [18] [ 980/1093] d_loss: 1.20814800, g_loss: 0.66050750\n",
      "Epoch: [18] [1000/1093] d_loss: 1.11870551, g_loss: 0.76751274\n",
      "save down\n",
      "Epoch: [18] [1020/1093] d_loss: 1.08732796, g_loss: 0.69929683\n",
      "Epoch: [18] [1040/1093] d_loss: 1.13094759, g_loss: 0.66103041\n",
      "Epoch: [18] [1060/1093] d_loss: 1.09859872, g_loss: 0.68068093\n",
      "Epoch: [18] [1080/1093] d_loss: 1.19172728, g_loss: 0.71336800\n",
      "Epoch: [19] [   0/1093] d_loss: 1.17887080, g_loss: 0.69612885\n",
      "save down\n",
      "Epoch: [19] [  20/1093] d_loss: 1.10589647, g_loss: 0.69425422\n",
      "Epoch: [19] [  40/1093] d_loss: 1.14340746, g_loss: 0.72285813\n",
      "Epoch: [19] [  60/1093] d_loss: 1.12111902, g_loss: 0.78236127\n",
      "Epoch: [19] [  80/1093] d_loss: 1.19959056, g_loss: 0.68554676\n",
      "Epoch: [19] [ 100/1093] d_loss: 1.08997679, g_loss: 0.69625181\n",
      "save down\n",
      "Epoch: [19] [ 120/1093] d_loss: 1.08637857, g_loss: 0.79970187\n",
      "Epoch: [19] [ 140/1093] d_loss: 1.13263357, g_loss: 0.71385479\n",
      "Epoch: [19] [ 160/1093] d_loss: 1.13864374, g_loss: 0.70251536\n",
      "Epoch: [19] [ 180/1093] d_loss: 1.15179777, g_loss: 0.64918238\n",
      "Epoch: [19] [ 200/1093] d_loss: 1.10704303, g_loss: 0.70704806\n",
      "save down\n",
      "Epoch: [19] [ 220/1093] d_loss: 1.17301333, g_loss: 0.67399937\n",
      "Epoch: [19] [ 240/1093] d_loss: 1.18633914, g_loss: 0.63095242\n",
      "Epoch: [19] [ 260/1093] d_loss: 1.08549690, g_loss: 0.77748895\n",
      "Epoch: [19] [ 280/1093] d_loss: 1.14666247, g_loss: 0.73269439\n",
      "Epoch: [19] [ 300/1093] d_loss: 1.17096090, g_loss: 0.67735803\n",
      "save down\n",
      "Epoch: [19] [ 320/1093] d_loss: 1.16573620, g_loss: 0.66320127\n",
      "Epoch: [19] [ 340/1093] d_loss: 1.10196531, g_loss: 0.73892176\n",
      "Epoch: [19] [ 360/1093] d_loss: 1.20381737, g_loss: 0.63530892\n",
      "Epoch: [19] [ 380/1093] d_loss: 1.06255841, g_loss: 0.71823895\n",
      "Epoch: [19] [ 400/1093] d_loss: 1.19537377, g_loss: 0.61483622\n",
      "save down\n",
      "Epoch: [19] [ 420/1093] d_loss: 1.15597427, g_loss: 0.71047813\n",
      "Epoch: [19] [ 440/1093] d_loss: 1.09167767, g_loss: 0.75387996\n",
      "Epoch: [19] [ 460/1093] d_loss: 1.09368742, g_loss: 0.67443740\n",
      "Epoch: [19] [ 480/1093] d_loss: 1.18465579, g_loss: 0.64444715\n",
      "Epoch: [19] [ 500/1093] d_loss: 1.14912474, g_loss: 0.71202672\n",
      "save down\n",
      "Epoch: [19] [ 520/1093] d_loss: 1.13781977, g_loss: 0.67006642\n",
      "Epoch: [19] [ 540/1093] d_loss: 1.15777016, g_loss: 0.61803401\n",
      "Epoch: [19] [ 560/1093] d_loss: 1.13810599, g_loss: 0.68916285\n",
      "Epoch: [19] [ 580/1093] d_loss: 1.09514308, g_loss: 0.69524103\n",
      "Epoch: [19] [ 600/1093] d_loss: 1.17884338, g_loss: 0.63582295\n",
      "save down\n",
      "Epoch: [19] [ 620/1093] d_loss: 1.02932668, g_loss: 0.82249117\n",
      "Epoch: [19] [ 640/1093] d_loss: 1.18184710, g_loss: 0.67803031\n",
      "Epoch: [19] [ 660/1093] d_loss: 1.08980298, g_loss: 0.68919897\n",
      "Epoch: [19] [ 680/1093] d_loss: 1.08918285, g_loss: 0.73666739\n",
      "Epoch: [19] [ 700/1093] d_loss: 1.11216092, g_loss: 0.66797614\n",
      "save down\n",
      "Epoch: [19] [ 720/1093] d_loss: 1.23249519, g_loss: 0.68860298\n",
      "Epoch: [19] [ 740/1093] d_loss: 1.03878641, g_loss: 0.79849589\n",
      "Epoch: [19] [ 760/1093] d_loss: 1.14441848, g_loss: 0.65649438\n",
      "Epoch: [19] [ 780/1093] d_loss: 1.09871197, g_loss: 0.72780371\n",
      "Epoch: [19] [ 800/1093] d_loss: 1.08532214, g_loss: 0.74965769\n",
      "save down\n",
      "Epoch: [19] [ 820/1093] d_loss: 1.10977960, g_loss: 0.73553014\n",
      "Epoch: [19] [ 840/1093] d_loss: 1.04282916, g_loss: 0.71881163\n",
      "Epoch: [19] [ 860/1093] d_loss: 1.12012589, g_loss: 0.75118154\n",
      "Epoch: [19] [ 880/1093] d_loss: 1.18058002, g_loss: 0.78045458\n",
      "Epoch: [19] [ 900/1093] d_loss: 1.15768075, g_loss: 0.64376366\n",
      "save down\n",
      "Epoch: [19] [ 920/1093] d_loss: 1.13588643, g_loss: 0.66137469\n",
      "Epoch: [19] [ 940/1093] d_loss: 1.24771941, g_loss: 0.63597280\n",
      "Epoch: [19] [ 960/1093] d_loss: 1.04956114, g_loss: 0.70128673\n",
      "Epoch: [19] [ 980/1093] d_loss: 1.11744976, g_loss: 0.70620495\n",
      "Epoch: [19] [1000/1093] d_loss: 0.99255741, g_loss: 0.81646752\n",
      "save down\n",
      "Epoch: [19] [1020/1093] d_loss: 1.06451082, g_loss: 0.71976584\n",
      "Epoch: [19] [1040/1093] d_loss: 1.14596140, g_loss: 0.64153415\n",
      "Epoch: [19] [1060/1093] d_loss: 1.17757154, g_loss: 0.61877537\n",
      "Epoch: [19] [1080/1093] d_loss: 1.23697495, g_loss: 0.66316319\n",
      "Epoch: [20] [   0/1093] d_loss: 1.09762239, g_loss: 0.67639822\n",
      "save down\n",
      "Epoch: [20] [  20/1093] d_loss: 1.20334280, g_loss: 0.64062655\n",
      "Epoch: [20] [  40/1093] d_loss: 1.10501170, g_loss: 0.68999529\n",
      "Epoch: [20] [  60/1093] d_loss: 1.13349009, g_loss: 0.80157912\n",
      "Epoch: [20] [  80/1093] d_loss: 1.27758777, g_loss: 0.59066904\n",
      "Epoch: [20] [ 100/1093] d_loss: 1.10603881, g_loss: 0.70352298\n",
      "save down\n",
      "Epoch: [20] [ 120/1093] d_loss: 1.15579128, g_loss: 0.67365199\n",
      "Epoch: [20] [ 140/1093] d_loss: 1.11650622, g_loss: 0.70889258\n",
      "Epoch: [20] [ 160/1093] d_loss: 1.14692307, g_loss: 0.68927240\n",
      "Epoch: [20] [ 180/1093] d_loss: 1.18116093, g_loss: 0.68404156\n",
      "Epoch: [20] [ 200/1093] d_loss: 0.95793176, g_loss: 0.86046791\n",
      "save down\n",
      "Epoch: [20] [ 220/1093] d_loss: 1.15944338, g_loss: 0.69467127\n",
      "Epoch: [20] [ 240/1093] d_loss: 1.14830089, g_loss: 0.73001277\n",
      "Epoch: [20] [ 260/1093] d_loss: 1.18718553, g_loss: 0.72533631\n",
      "Epoch: [20] [ 280/1093] d_loss: 1.15306032, g_loss: 0.69517732\n",
      "Epoch: [20] [ 300/1093] d_loss: 1.12180614, g_loss: 0.73188460\n",
      "save down\n",
      "Epoch: [20] [ 320/1093] d_loss: 1.16519260, g_loss: 0.64190423\n",
      "Epoch: [20] [ 340/1093] d_loss: 1.10707247, g_loss: 0.68059802\n",
      "Epoch: [20] [ 360/1093] d_loss: 1.12753105, g_loss: 0.69773018\n",
      "Epoch: [20] [ 380/1093] d_loss: 1.10774696, g_loss: 0.72306228\n",
      "Epoch: [20] [ 400/1093] d_loss: 1.15866840, g_loss: 0.67422444\n",
      "save down\n",
      "Epoch: [20] [ 420/1093] d_loss: 1.18254352, g_loss: 0.63560742\n",
      "Epoch: [20] [ 440/1093] d_loss: 1.15119720, g_loss: 0.65722543\n",
      "Epoch: [20] [ 460/1093] d_loss: 1.16909695, g_loss: 0.71626937\n",
      "Epoch: [20] [ 480/1093] d_loss: 1.17038131, g_loss: 0.66410637\n",
      "Epoch: [20] [ 500/1093] d_loss: 1.13541317, g_loss: 0.74250948\n",
      "save down\n",
      "Epoch: [20] [ 520/1093] d_loss: 1.11006129, g_loss: 0.73875785\n",
      "Epoch: [20] [ 540/1093] d_loss: 1.10405445, g_loss: 0.65316296\n",
      "Epoch: [20] [ 560/1093] d_loss: 1.17272997, g_loss: 0.66772676\n",
      "Epoch: [20] [ 580/1093] d_loss: 1.17459953, g_loss: 0.73219573\n",
      "Epoch: [20] [ 600/1093] d_loss: 1.11786985, g_loss: 0.67403340\n",
      "save down\n",
      "Epoch: [20] [ 620/1093] d_loss: 1.11071599, g_loss: 0.76596916\n",
      "Epoch: [20] [ 640/1093] d_loss: 1.14122283, g_loss: 0.64657617\n",
      "Epoch: [20] [ 660/1093] d_loss: 1.12784052, g_loss: 0.67606354\n",
      "Epoch: [20] [ 680/1093] d_loss: 1.09199381, g_loss: 0.70491207\n",
      "Epoch: [20] [ 700/1093] d_loss: 1.08835316, g_loss: 0.68867731\n",
      "save down\n",
      "Epoch: [20] [ 720/1093] d_loss: 1.05627847, g_loss: 0.83377111\n",
      "Epoch: [20] [ 740/1093] d_loss: 1.10855007, g_loss: 0.66896665\n",
      "Epoch: [20] [ 760/1093] d_loss: 1.03455329, g_loss: 0.78994471\n",
      "Epoch: [20] [ 780/1093] d_loss: 1.03605974, g_loss: 0.77160025\n",
      "Epoch: [20] [ 800/1093] d_loss: 1.05497873, g_loss: 0.77170539\n",
      "save down\n",
      "Epoch: [20] [ 820/1093] d_loss: 1.06465101, g_loss: 0.75778902\n",
      "Epoch: [20] [ 840/1093] d_loss: 1.04252899, g_loss: 0.75491059\n",
      "Epoch: [20] [ 860/1093] d_loss: 1.05811870, g_loss: 0.77341104\n",
      "Epoch: [20] [ 880/1093] d_loss: 1.05144906, g_loss: 0.72467214\n",
      "Epoch: [20] [ 900/1093] d_loss: 1.12860620, g_loss: 0.71170151\n",
      "save down\n",
      "Epoch: [20] [ 920/1093] d_loss: 1.07424617, g_loss: 0.71862340\n",
      "Epoch: [20] [ 940/1093] d_loss: 1.19290245, g_loss: 0.63124037\n",
      "Epoch: [20] [ 960/1093] d_loss: 0.98686361, g_loss: 0.81480122\n",
      "Epoch: [20] [ 980/1093] d_loss: 1.12922716, g_loss: 0.74647993\n",
      "Epoch: [20] [1000/1093] d_loss: 1.18825841, g_loss: 0.66048938\n",
      "save down\n",
      "Epoch: [20] [1020/1093] d_loss: 1.07150054, g_loss: 0.72888130\n",
      "Epoch: [20] [1040/1093] d_loss: 1.06795943, g_loss: 0.80227488\n",
      "Epoch: [20] [1060/1093] d_loss: 1.10312653, g_loss: 0.71562743\n",
      "Epoch: [20] [1080/1093] d_loss: 1.23186255, g_loss: 0.59562325\n",
      "Epoch: [21] [   0/1093] d_loss: 1.04889011, g_loss: 0.76301903\n",
      "save down\n",
      "Epoch: [21] [  20/1093] d_loss: 1.02461076, g_loss: 0.85156393\n",
      "Epoch: [21] [  40/1093] d_loss: 1.17626572, g_loss: 0.67195404\n",
      "Epoch: [21] [  60/1093] d_loss: 1.04638422, g_loss: 0.76540983\n",
      "Epoch: [21] [  80/1093] d_loss: 1.11587954, g_loss: 0.71426558\n",
      "Epoch: [21] [ 100/1093] d_loss: 1.19797087, g_loss: 0.68992400\n",
      "save down\n",
      "Epoch: [21] [ 120/1093] d_loss: 1.05743754, g_loss: 0.83863580\n",
      "Epoch: [21] [ 140/1093] d_loss: 1.10780644, g_loss: 0.71701527\n",
      "Epoch: [21] [ 160/1093] d_loss: 1.12301564, g_loss: 0.65241241\n",
      "Epoch: [21] [ 180/1093] d_loss: 1.15610063, g_loss: 0.67794800\n",
      "Epoch: [21] [ 200/1093] d_loss: 0.98088276, g_loss: 0.87737930\n",
      "save down\n",
      "Epoch: [21] [ 220/1093] d_loss: 1.14341927, g_loss: 0.68091035\n",
      "Epoch: [21] [ 240/1093] d_loss: 1.04701066, g_loss: 0.77687705\n",
      "Epoch: [21] [ 260/1093] d_loss: 1.11112118, g_loss: 0.76948768\n",
      "Epoch: [21] [ 280/1093] d_loss: 1.10135889, g_loss: 0.70901185\n",
      "Epoch: [21] [ 300/1093] d_loss: 1.14398980, g_loss: 0.70252049\n",
      "save down\n",
      "Epoch: [21] [ 320/1093] d_loss: 1.11768734, g_loss: 0.65939963\n",
      "Epoch: [21] [ 340/1093] d_loss: 0.93948364, g_loss: 0.88637388\n",
      "Epoch: [21] [ 360/1093] d_loss: 1.19741762, g_loss: 0.64745283\n",
      "Epoch: [21] [ 380/1093] d_loss: 1.05734074, g_loss: 0.70191473\n",
      "Epoch: [21] [ 400/1093] d_loss: 1.07993972, g_loss: 0.70433342\n",
      "save down\n",
      "Epoch: [21] [ 420/1093] d_loss: 1.13194776, g_loss: 0.72523367\n",
      "Epoch: [21] [ 440/1093] d_loss: 1.06859517, g_loss: 0.74275929\n",
      "Epoch: [21] [ 460/1093] d_loss: 1.07071912, g_loss: 0.75378984\n",
      "Epoch: [21] [ 480/1093] d_loss: 1.00258362, g_loss: 0.81054413\n",
      "Epoch: [21] [ 500/1093] d_loss: 1.11615992, g_loss: 0.70072931\n",
      "save down\n",
      "Epoch: [21] [ 520/1093] d_loss: 1.11170638, g_loss: 0.77809429\n",
      "Epoch: [21] [ 540/1093] d_loss: 1.05887187, g_loss: 0.69661927\n",
      "Epoch: [21] [ 560/1093] d_loss: 1.17649555, g_loss: 0.63158000\n",
      "Epoch: [21] [ 580/1093] d_loss: 1.06747031, g_loss: 0.74600393\n",
      "Epoch: [21] [ 600/1093] d_loss: 1.10112715, g_loss: 0.67946267\n",
      "save down\n",
      "Epoch: [21] [ 620/1093] d_loss: 1.01742268, g_loss: 0.84875715\n",
      "Epoch: [21] [ 640/1093] d_loss: 1.03858805, g_loss: 0.73076880\n",
      "Epoch: [21] [ 660/1093] d_loss: 1.04023671, g_loss: 0.72045326\n",
      "Epoch: [21] [ 680/1093] d_loss: 1.10459614, g_loss: 0.72968888\n",
      "Epoch: [21] [ 700/1093] d_loss: 1.02104974, g_loss: 0.77858716\n",
      "save down\n",
      "Epoch: [21] [ 720/1093] d_loss: 1.03759372, g_loss: 0.75881267\n",
      "Epoch: [21] [ 740/1093] d_loss: 1.09985495, g_loss: 0.70727819\n",
      "Epoch: [21] [ 760/1093] d_loss: 1.09680486, g_loss: 0.72724009\n",
      "Epoch: [21] [ 780/1093] d_loss: 1.12427413, g_loss: 0.67456222\n",
      "Epoch: [21] [ 800/1093] d_loss: 1.05240703, g_loss: 0.70210373\n",
      "save down\n",
      "Epoch: [21] [ 820/1093] d_loss: 1.03583217, g_loss: 0.76066256\n",
      "Epoch: [21] [ 840/1093] d_loss: 0.95843041, g_loss: 0.79901421\n",
      "Epoch: [21] [ 860/1093] d_loss: 1.11817646, g_loss: 0.65479964\n",
      "Epoch: [21] [ 880/1093] d_loss: 1.07451653, g_loss: 0.81288707\n",
      "Epoch: [21] [ 900/1093] d_loss: 1.06095386, g_loss: 0.74543196\n",
      "save down\n",
      "Epoch: [21] [ 920/1093] d_loss: 1.10696518, g_loss: 0.67360485\n",
      "Epoch: [21] [ 940/1093] d_loss: 1.08834291, g_loss: 0.68849796\n",
      "Epoch: [21] [ 960/1093] d_loss: 1.02692556, g_loss: 0.82979929\n",
      "Epoch: [21] [ 980/1093] d_loss: 1.14710259, g_loss: 0.70010835\n",
      "Epoch: [21] [1000/1093] d_loss: 1.16483974, g_loss: 0.67479610\n",
      "save down\n",
      "Epoch: [21] [1020/1093] d_loss: 1.11963856, g_loss: 0.65408283\n",
      "Epoch: [21] [1040/1093] d_loss: 1.06405282, g_loss: 0.69865543\n",
      "Epoch: [21] [1060/1093] d_loss: 1.01348400, g_loss: 0.76518083\n",
      "Epoch: [21] [1080/1093] d_loss: 1.06883490, g_loss: 0.72932094\n",
      "Epoch: [22] [   0/1093] d_loss: 1.11336231, g_loss: 0.74899119\n",
      "save down\n",
      "Epoch: [22] [  20/1093] d_loss: 1.17029440, g_loss: 0.64275432\n",
      "Epoch: [22] [  40/1093] d_loss: 1.10280275, g_loss: 0.73979712\n",
      "Epoch: [22] [  60/1093] d_loss: 1.06487310, g_loss: 0.74518895\n",
      "Epoch: [22] [  80/1093] d_loss: 1.14749575, g_loss: 0.66716003\n",
      "Epoch: [22] [ 100/1093] d_loss: 1.11238563, g_loss: 0.64530116\n",
      "save down\n",
      "Epoch: [22] [ 120/1093] d_loss: 1.09039259, g_loss: 0.72604311\n",
      "Epoch: [22] [ 140/1093] d_loss: 1.12977481, g_loss: 0.69407701\n",
      "Epoch: [22] [ 160/1093] d_loss: 1.10220027, g_loss: 0.74648207\n",
      "Epoch: [22] [ 180/1093] d_loss: 1.13549852, g_loss: 0.64568394\n",
      "Epoch: [22] [ 200/1093] d_loss: 0.97891563, g_loss: 0.83940256\n",
      "save down\n",
      "Epoch: [22] [ 220/1093] d_loss: 1.06862497, g_loss: 0.79921383\n",
      "Epoch: [22] [ 240/1093] d_loss: 1.00331283, g_loss: 0.76219058\n",
      "Epoch: [22] [ 260/1093] d_loss: 1.11028147, g_loss: 0.77317727\n",
      "Epoch: [22] [ 280/1093] d_loss: 1.17508388, g_loss: 0.68693537\n",
      "Epoch: [22] [ 300/1093] d_loss: 1.07612836, g_loss: 0.80426520\n",
      "save down\n",
      "Epoch: [22] [ 320/1093] d_loss: 1.08528471, g_loss: 0.69237804\n",
      "Epoch: [22] [ 340/1093] d_loss: 1.05675781, g_loss: 0.73044169\n",
      "Epoch: [22] [ 360/1093] d_loss: 1.14960849, g_loss: 0.66310036\n",
      "Epoch: [22] [ 380/1093] d_loss: 1.04789066, g_loss: 0.70679986\n",
      "Epoch: [22] [ 400/1093] d_loss: 1.19935632, g_loss: 0.68929118\n",
      "save down\n",
      "Epoch: [22] [ 420/1093] d_loss: 1.10629833, g_loss: 0.65784913\n",
      "Epoch: [22] [ 440/1093] d_loss: 1.10564101, g_loss: 0.68000919\n",
      "Epoch: [22] [ 460/1093] d_loss: 1.11219907, g_loss: 0.69752109\n",
      "Epoch: [22] [ 480/1093] d_loss: 1.08192122, g_loss: 0.67074943\n",
      "Epoch: [22] [ 500/1093] d_loss: 1.13609576, g_loss: 0.70145786\n",
      "save down\n",
      "Epoch: [22] [ 520/1093] d_loss: 0.98848295, g_loss: 0.84519118\n",
      "Epoch: [22] [ 540/1093] d_loss: 1.00755858, g_loss: 0.72099811\n",
      "Epoch: [22] [ 560/1093] d_loss: 1.11934674, g_loss: 0.70538187\n",
      "Epoch: [22] [ 580/1093] d_loss: 1.09597361, g_loss: 0.66638184\n",
      "Epoch: [22] [ 600/1093] d_loss: 1.21293545, g_loss: 0.61383760\n",
      "save down\n",
      "Epoch: [22] [ 620/1093] d_loss: 1.06881094, g_loss: 0.77652830\n",
      "Epoch: [22] [ 640/1093] d_loss: 1.09583211, g_loss: 0.72161961\n",
      "Epoch: [22] [ 660/1093] d_loss: 1.09554338, g_loss: 0.71662259\n",
      "Epoch: [22] [ 680/1093] d_loss: 1.01944101, g_loss: 0.80054939\n",
      "Epoch: [22] [ 700/1093] d_loss: 1.08731925, g_loss: 0.69743299\n",
      "save down\n",
      "Epoch: [22] [ 720/1093] d_loss: 0.99209821, g_loss: 0.82788408\n",
      "Epoch: [22] [ 740/1093] d_loss: 1.18046677, g_loss: 0.61500835\n",
      "Epoch: [22] [ 760/1093] d_loss: 1.05788267, g_loss: 0.76157469\n",
      "Epoch: [22] [ 780/1093] d_loss: 1.09265232, g_loss: 0.71604955\n",
      "Epoch: [22] [ 800/1093] d_loss: 1.12419128, g_loss: 0.73006028\n",
      "save down\n",
      "Epoch: [22] [ 820/1093] d_loss: 0.94072479, g_loss: 0.89360154\n",
      "Epoch: [22] [ 840/1093] d_loss: 0.96676123, g_loss: 0.80990863\n",
      "Epoch: [22] [ 860/1093] d_loss: 1.07892752, g_loss: 0.76220679\n",
      "Epoch: [22] [ 880/1093] d_loss: 1.01065278, g_loss: 0.75287187\n",
      "Epoch: [22] [ 900/1093] d_loss: 1.09618950, g_loss: 0.75606191\n",
      "save down\n",
      "Epoch: [22] [ 920/1093] d_loss: 1.14765072, g_loss: 0.70273411\n",
      "Epoch: [22] [ 940/1093] d_loss: 1.16949213, g_loss: 0.65399599\n",
      "Epoch: [22] [ 960/1093] d_loss: 1.09002161, g_loss: 0.65758365\n",
      "Epoch: [22] [ 980/1093] d_loss: 1.10814226, g_loss: 0.67617059\n",
      "Epoch: [22] [1000/1093] d_loss: 1.03559208, g_loss: 0.82170945\n",
      "save down\n",
      "Epoch: [22] [1020/1093] d_loss: 1.00801694, g_loss: 0.74256265\n",
      "Epoch: [22] [1040/1093] d_loss: 1.03777909, g_loss: 0.74304211\n",
      "Epoch: [22] [1060/1093] d_loss: 1.09164870, g_loss: 0.78296113\n",
      "Epoch: [22] [1080/1093] d_loss: 1.10013795, g_loss: 0.69514018\n",
      "Epoch: [23] [   0/1093] d_loss: 1.07200336, g_loss: 0.69169295\n",
      "save down\n",
      "Epoch: [23] [  20/1093] d_loss: 1.06166065, g_loss: 0.74926996\n",
      "Epoch: [23] [  40/1093] d_loss: 1.15787351, g_loss: 0.76938534\n",
      "Epoch: [23] [  60/1093] d_loss: 1.00021410, g_loss: 0.80660462\n",
      "Epoch: [23] [  80/1093] d_loss: 1.05445015, g_loss: 0.82856268\n",
      "Epoch: [23] [ 100/1093] d_loss: 1.06244361, g_loss: 0.71782374\n",
      "save down\n",
      "Epoch: [23] [ 120/1093] d_loss: 1.00669193, g_loss: 0.80364132\n",
      "Epoch: [23] [ 140/1093] d_loss: 1.05705678, g_loss: 0.75672543\n",
      "Epoch: [23] [ 160/1093] d_loss: 1.12379646, g_loss: 0.68300056\n",
      "Epoch: [23] [ 180/1093] d_loss: 1.06013751, g_loss: 0.66856444\n",
      "Epoch: [23] [ 200/1093] d_loss: 0.91806167, g_loss: 0.92240858\n",
      "save down\n",
      "Epoch: [23] [ 220/1093] d_loss: 1.10057724, g_loss: 0.74635535\n",
      "Epoch: [23] [ 240/1093] d_loss: 1.00673044, g_loss: 0.83003813\n",
      "Epoch: [23] [ 260/1093] d_loss: 0.99366474, g_loss: 0.84744251\n",
      "Epoch: [23] [ 280/1093] d_loss: 1.14385235, g_loss: 0.68093133\n",
      "Epoch: [23] [ 300/1093] d_loss: 1.16069782, g_loss: 0.69335616\n",
      "save down\n",
      "Epoch: [23] [ 320/1093] d_loss: 1.20313931, g_loss: 0.60722047\n",
      "Epoch: [23] [ 340/1093] d_loss: 1.00926673, g_loss: 0.76929736\n",
      "Epoch: [23] [ 360/1093] d_loss: 1.10783172, g_loss: 0.71483648\n",
      "Epoch: [23] [ 380/1093] d_loss: 1.03262675, g_loss: 0.70367354\n",
      "Epoch: [23] [ 400/1093] d_loss: 1.08476138, g_loss: 0.70948738\n",
      "save down\n",
      "Epoch: [23] [ 420/1093] d_loss: 1.04054058, g_loss: 0.72916031\n",
      "Epoch: [23] [ 440/1093] d_loss: 1.00252271, g_loss: 0.77911723\n",
      "Epoch: [23] [ 460/1093] d_loss: 1.17120051, g_loss: 0.65535200\n",
      "Epoch: [23] [ 480/1093] d_loss: 1.02473783, g_loss: 0.77722609\n",
      "Epoch: [23] [ 500/1093] d_loss: 1.01246643, g_loss: 0.80738771\n",
      "save down\n",
      "Epoch: [23] [ 520/1093] d_loss: 1.03791380, g_loss: 0.78289938\n",
      "Epoch: [23] [ 540/1093] d_loss: 1.06096458, g_loss: 0.68441337\n",
      "Epoch: [23] [ 560/1093] d_loss: 1.01722836, g_loss: 0.78640330\n",
      "Epoch: [23] [ 580/1093] d_loss: 1.07010710, g_loss: 0.73674476\n",
      "Epoch: [23] [ 600/1093] d_loss: 1.05538940, g_loss: 0.74034095\n",
      "save down\n",
      "Epoch: [23] [ 620/1093] d_loss: 1.12300789, g_loss: 0.78830779\n",
      "Epoch: [23] [ 640/1093] d_loss: 1.16985726, g_loss: 0.67981118\n",
      "Epoch: [23] [ 660/1093] d_loss: 1.04682398, g_loss: 0.73536515\n",
      "Epoch: [23] [ 680/1093] d_loss: 1.04494715, g_loss: 0.85912681\n",
      "Epoch: [23] [ 700/1093] d_loss: 1.09840393, g_loss: 0.68867105\n",
      "save down\n",
      "Epoch: [23] [ 720/1093] d_loss: 1.01189303, g_loss: 0.78369570\n",
      "Epoch: [23] [ 740/1093] d_loss: 1.09537554, g_loss: 0.73967695\n",
      "Epoch: [23] [ 760/1093] d_loss: 1.03231394, g_loss: 0.87691581\n",
      "Epoch: [23] [ 780/1093] d_loss: 1.03064680, g_loss: 0.73724377\n",
      "Epoch: [23] [ 800/1093] d_loss: 0.99969256, g_loss: 0.77537227\n",
      "save down\n",
      "Epoch: [23] [ 820/1093] d_loss: 1.04455233, g_loss: 0.76883274\n",
      "Epoch: [23] [ 840/1093] d_loss: 0.91709816, g_loss: 0.82596815\n",
      "Epoch: [23] [ 860/1093] d_loss: 1.07515049, g_loss: 0.73620927\n",
      "Epoch: [23] [ 880/1093] d_loss: 1.05813062, g_loss: 0.70261919\n",
      "Epoch: [23] [ 900/1093] d_loss: 0.99165756, g_loss: 0.76843232\n",
      "save down\n",
      "Epoch: [23] [ 920/1093] d_loss: 1.12637877, g_loss: 0.65455616\n",
      "Epoch: [23] [ 940/1093] d_loss: 1.20211673, g_loss: 0.59728169\n",
      "Epoch: [23] [ 960/1093] d_loss: 1.00800669, g_loss: 0.69812131\n",
      "Epoch: [23] [ 980/1093] d_loss: 1.11692584, g_loss: 0.70068741\n",
      "Epoch: [23] [1000/1093] d_loss: 1.00204134, g_loss: 0.90840018\n",
      "save down\n",
      "Epoch: [23] [1020/1093] d_loss: 1.02247679, g_loss: 0.79154944\n",
      "Epoch: [23] [1040/1093] d_loss: 1.02807426, g_loss: 0.76386553\n",
      "Epoch: [23] [1060/1093] d_loss: 1.09002280, g_loss: 0.67599976\n",
      "Epoch: [23] [1080/1093] d_loss: 1.16196704, g_loss: 0.64114416\n",
      "Epoch: [24] [   0/1093] d_loss: 1.09417355, g_loss: 0.75558776\n",
      "save down\n",
      "Epoch: [24] [  20/1093] d_loss: 1.07791758, g_loss: 0.71996605\n",
      "Epoch: [24] [  40/1093] d_loss: 1.12410605, g_loss: 0.75308400\n",
      "Epoch: [24] [  60/1093] d_loss: 1.14216948, g_loss: 0.71008754\n",
      "Epoch: [24] [  80/1093] d_loss: 1.07211173, g_loss: 0.76415741\n",
      "Epoch: [24] [ 100/1093] d_loss: 1.01527190, g_loss: 0.79721302\n",
      "save down\n",
      "Epoch: [24] [ 120/1093] d_loss: 1.12494481, g_loss: 0.73854333\n",
      "Epoch: [24] [ 140/1093] d_loss: 1.01200938, g_loss: 0.81157273\n",
      "Epoch: [24] [ 160/1093] d_loss: 1.08189106, g_loss: 0.69969082\n",
      "Epoch: [24] [ 180/1093] d_loss: 1.10367084, g_loss: 0.66442871\n",
      "Epoch: [24] [ 200/1093] d_loss: 0.93365371, g_loss: 0.85444945\n",
      "save down\n",
      "Epoch: [24] [ 220/1093] d_loss: 1.05674982, g_loss: 0.75499427\n",
      "Epoch: [24] [ 240/1093] d_loss: 0.92050970, g_loss: 0.89835298\n",
      "Epoch: [24] [ 260/1093] d_loss: 0.97644609, g_loss: 0.87923872\n",
      "Epoch: [24] [ 280/1093] d_loss: 1.06780386, g_loss: 0.72203082\n",
      "Epoch: [24] [ 300/1093] d_loss: 1.09152842, g_loss: 0.75700748\n",
      "save down\n",
      "Epoch: [24] [ 320/1093] d_loss: 1.10132229, g_loss: 0.65272248\n",
      "Epoch: [24] [ 340/1093] d_loss: 1.03071833, g_loss: 0.82591391\n",
      "Epoch: [24] [ 360/1093] d_loss: 1.12376940, g_loss: 0.65350711\n",
      "Epoch: [24] [ 380/1093] d_loss: 0.96730500, g_loss: 0.75408435\n",
      "Epoch: [24] [ 400/1093] d_loss: 1.01845360, g_loss: 0.76247615\n",
      "save down\n",
      "Epoch: [24] [ 420/1093] d_loss: 1.03924203, g_loss: 0.78170633\n",
      "Epoch: [24] [ 440/1093] d_loss: 1.09266746, g_loss: 0.68589604\n",
      "Epoch: [24] [ 460/1093] d_loss: 1.05329704, g_loss: 0.78182936\n",
      "Epoch: [24] [ 480/1093] d_loss: 1.03206134, g_loss: 0.75247741\n",
      "Epoch: [24] [ 500/1093] d_loss: 1.06627965, g_loss: 0.78560150\n",
      "save down\n",
      "Epoch: [24] [ 520/1093] d_loss: 1.02091193, g_loss: 0.89098555\n",
      "Epoch: [24] [ 540/1093] d_loss: 1.06585085, g_loss: 0.69774014\n",
      "Epoch: [24] [ 560/1093] d_loss: 1.05314827, g_loss: 0.74125934\n",
      "Epoch: [24] [ 580/1093] d_loss: 1.08125114, g_loss: 0.66821086\n",
      "Epoch: [24] [ 600/1093] d_loss: 1.11022079, g_loss: 0.66881716\n",
      "save down\n",
      "Epoch: [24] [ 620/1093] d_loss: 1.08309460, g_loss: 0.74790120\n",
      "Epoch: [24] [ 640/1093] d_loss: 1.15154505, g_loss: 0.64418101\n",
      "Epoch: [24] [ 660/1093] d_loss: 1.15211964, g_loss: 0.66135621\n",
      "Epoch: [24] [ 680/1093] d_loss: 0.96287429, g_loss: 0.82336152\n",
      "Epoch: [24] [ 700/1093] d_loss: 0.97576678, g_loss: 0.82402438\n",
      "save down\n",
      "Epoch: [24] [ 720/1093] d_loss: 0.96794289, g_loss: 0.77840734\n",
      "Epoch: [24] [ 740/1093] d_loss: 1.08684981, g_loss: 0.68319809\n",
      "Epoch: [24] [ 760/1093] d_loss: 0.99787724, g_loss: 0.79640234\n",
      "Epoch: [24] [ 780/1093] d_loss: 1.01169944, g_loss: 0.73182094\n",
      "Epoch: [24] [ 800/1093] d_loss: 0.97165954, g_loss: 0.80203050\n",
      "save down\n",
      "Epoch: [24] [ 820/1093] d_loss: 0.98840499, g_loss: 0.78179789\n",
      "Epoch: [24] [ 840/1093] d_loss: 1.01332760, g_loss: 0.75794047\n",
      "Epoch: [24] [ 860/1093] d_loss: 0.98820007, g_loss: 0.85057163\n",
      "Epoch: [24] [ 880/1093] d_loss: 1.04320204, g_loss: 0.72640669\n",
      "Epoch: [24] [ 900/1093] d_loss: 1.08433390, g_loss: 0.67861509\n",
      "save down\n",
      "Epoch: [24] [ 920/1093] d_loss: 1.05019951, g_loss: 0.72995782\n",
      "Epoch: [24] [ 940/1093] d_loss: 1.14670908, g_loss: 0.64328212\n",
      "Epoch: [24] [ 960/1093] d_loss: 0.99620610, g_loss: 0.83240390\n",
      "Epoch: [24] [ 980/1093] d_loss: 1.15381539, g_loss: 0.63325191\n",
      "Epoch: [24] [1000/1093] d_loss: 0.98067129, g_loss: 0.87082338\n",
      "save down\n",
      "Epoch: [24] [1020/1093] d_loss: 0.96707857, g_loss: 0.85686487\n",
      "Epoch: [24] [1040/1093] d_loss: 1.01741481, g_loss: 0.74152255\n",
      "Epoch: [24] [1060/1093] d_loss: 1.01617301, g_loss: 0.75051665\n",
      "Epoch: [24] [1080/1093] d_loss: 1.06075060, g_loss: 0.77012992\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval():\n",
    "    \n",
    "    test_dir = './eval'\n",
    "    checkpoint_dir = './logs'\n",
    "    \n",
    "    z = tf.placeholder(tf.float32, [None, 100], name='z')\n",
    "    \n",
    "    G = generator(z, train=False)\n",
    "    sample_z = np.random.uniform(-1, 1, size=(BATCH_SIZE, 100))\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        print('Reading Checkpoints...')\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    \n",
    "        if ckpt:\n",
    "            saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "        \n",
    "        samples = sess.run(G, feed_dict = {z: sample_z})\n",
    "    \n",
    "        save_images(samples, [8, 8], os.path.join(test_dir, 'test.png'))\n",
    "        print('Sample image saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Checkpoints...\n",
      "Sample image saved.\n"
     ]
    }
   ],
   "source": [
    "eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
